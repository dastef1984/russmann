{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this testing was to train and evaluate a BPR and an ItemKNN model using the RecBole library on a custom dataset derived from medical reviews and compare it to the results from the MovieLens dataset. The process involved downloading, extracting, and inspecting the MovieLens dataset to understand its structure. Similarly, the medical dataset was prepared by merging train and test datasets, assigning unique identifiers, and converting dates to timestamps. The interaction files were formatted to match RecBole's expectations. Despite structuring the medical dataset similar to MovieLens, the BPR model and the ItemKNN model did not produce meaningful results with the custom dataset. The model training and evaluation worked seamlessly with MovieLens data but not with the custom medical dataset, leading to the conclusion that further investigation into the data preprocessing or model configuration might be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) In this step I inspect the interaction file of the ML100K dataset that is used from recbole. I downloaded this file that is part of the recbole framework manually from another source, to have a basis for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M Interaction File:\n",
      "   user_id:token  item_id:token  rating:float  timestamp:float\n",
      "0              1           1193             5        978300760\n",
      "1              1            661             3        978302109\n",
      "2              1            914             3        978301968\n",
      "3              1           3408             4        978300275\n",
      "4              1           2355             5        978824291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load and inspect the interaction file\n",
    "interaction_df = pd.read_csv('ml-1m.inter', sep='\\t')\n",
    "print(\"ML1M Interaction File:\")\n",
    "print(interaction_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) In the second step, I loaded the medical data set, which is divided into two parts (training and testing), and carried out an initial data exploration to get an impression of the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Data Train Dataset:\n",
      "   uniqueID                  drugName                     condition  \\\n",
      "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
      "1     95260                Guanfacine                          ADHD   \n",
      "2     92703                    Lybrel                 Birth Control   \n",
      "3    138000                Ortho Evra                 Birth Control   \n",
      "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
      "\n",
      "                                              review  rating       date  \\\n",
      "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
      "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
      "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
      "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
      "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
      "\n",
      "   usefulCount  \n",
      "0           27  \n",
      "1          192  \n",
      "2           17  \n",
      "3           10  \n",
      "4           37  \n",
      "\n",
      "Medical Data Test Dataset:\n",
      "   uniqueID         drugName                     condition  \\\n",
      "0    163740      Mirtazapine                    Depression   \n",
      "1    206473       Mesalamine  Crohn's Disease, Maintenance   \n",
      "2    159672          Bactrim       Urinary Tract Infection   \n",
      "3     39293         Contrave                   Weight Loss   \n",
      "4     97768  Cyclafem 1 / 35                 Birth Control   \n",
      "\n",
      "                                              review  rating       date  \\\n",
      "0  \"I&#039;ve tried a few antidepressants over th...      10  28-Feb-12   \n",
      "1  \"My son has Crohn&#039;s disease and has done ...       8  17-May-09   \n",
      "2                      \"Quick reduction of symptoms\"       9  29-Sep-17   \n",
      "3  \"Contrave combines drugs that were used for al...       9   5-Mar-17   \n",
      "4  \"I have been on this birth control for one cyc...       9  22-Oct-15   \n",
      "\n",
      "   usefulCount  \n",
      "0           22  \n",
      "1           17  \n",
      "2            3  \n",
      "3           35  \n",
      "4            4  \n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('drugsComTrain_raw.csv')\n",
    "test_df = pd.read_csv('drugsComTest_raw.csv')\n",
    "\n",
    "# Print the first few rows of the train dataset\n",
    "print(\"Medical Data Train Dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Print the first few rows of the test dataset\n",
    "print(\"\\nMedical Data Test Dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Then I merged the training and test data sets and prepared the data so that the column names and format are identical to those of the ML100K interaction file. I then saved the adjusted data under “custom.inter” in order to have an *.inter-interaction file available in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged and adjusted Medical Data Sample:\n",
      "   user_id:token  item_id:token  rating:float  timestamp:float\n",
      "0         191228           3425             9     1.337472e+09\n",
      "1          88331           1539             8     1.272326e+09\n",
      "2          85964           1986             5     1.260749e+09\n",
      "3         127958           2450             8     1.446509e+09\n",
      "4          33057            554             9     1.480205e+09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine train and test datasets\n",
    "df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Assign unique identifiers\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "df['user_id'] = user_encoder.fit_transform(df['uniqueID'])\n",
    "df['item_id'] = item_encoder.fit_transform(df['drugName'])\n",
    "\n",
    "# Convert date to timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['date'], format='%d-%b-%y').astype(int) / 10**9\n",
    "\n",
    "# Create the interaction file\n",
    "interaction_df = df[['user_id', 'item_id', 'rating', 'timestamp']]\n",
    "interaction_df.columns = ['user_id:token', 'item_id:token', 'rating:float', 'timestamp:float']\n",
    "interaction_df.to_csv('custom.inter', sep='\\t', index=False)\n",
    "\n",
    "# Verify the interaction file\n",
    "print(\"Merged and adjusted Medical Data Sample:\")\n",
    "print(interaction_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Then I load both interaction files (*.inter) and have the first lines and information about the data sets displayed again. As far as can be seen, the two data sets are identical in structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M Interaction File:\n",
      "   user_id:token  item_id:token  rating:float  timestamp:float\n",
      "0              1           1193             5        978300760\n",
      "1              1            661             3        978302109\n",
      "2              1            914             3        978301968\n",
      "3              1           3408             4        978300275\n",
      "4              1           2355             5        978824291\n",
      "Custom Interaction File:\n",
      "   user_id:token  item_id:token  rating:float  timestamp:float\n",
      "0         191228           3425             9     1.337472e+09\n",
      "1          88331           1539             8     1.272326e+09\n",
      "2          85964           1986             5     1.260749e+09\n",
      "3         127958           2450             8     1.446509e+09\n",
      "4          33057            554             9     1.480205e+09\n",
      "\n",
      "ML1M Interaction File Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count    Dtype\n",
      "---  ------           --------------    -----\n",
      " 0   user_id:token    1000209 non-null  int64\n",
      " 1   item_id:token    1000209 non-null  int64\n",
      " 2   rating:float     1000209 non-null  int64\n",
      " 3   timestamp:float  1000209 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 30.5 MB\n",
      "None\n",
      "\n",
      "Custom Interaction File Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215063 entries, 0 to 215062\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   user_id:token    215063 non-null  int64  \n",
      " 1   item_id:token    215063 non-null  int64  \n",
      " 2   rating:float     215063 non-null  int64  \n",
      " 3   timestamp:float  215063 non-null  float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 6.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the interaction files\n",
    "ml1m_inter = pd.read_csv('ml-1m.inter', sep='\\t')\n",
    "custom_inter = pd.read_csv('custom.inter', sep='\\t')\n",
    "\n",
    "# Print the first few rows of the interaction files\n",
    "print(\"ML1M Interaction File:\")\n",
    "print(ml1m_inter.head())\n",
    "\n",
    "print(\"Custom Interaction File:\")\n",
    "print(custom_inter.head())\n",
    "\n",
    "# Check for missing values and data types\n",
    "print(\"\\nML1M Interaction File Info:\")\n",
    "print(ml1m_inter.info())\n",
    "\n",
    "print(\"\\nCustom Interaction File Info:\")\n",
    "print(custom_inter.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BPR with Custom (Medical) Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 Aug 17:34    INFO  ['/home/stef/.local/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/home/stef/.local/share/jupyter/runtime/kernel-57aa8a76-cc89-4f61-b316-dca3de1caa64.json']\n",
      "20 Aug 17:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/custom\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54/2870578762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training BPR with Custom (Medical) Dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#result = run_recbole(model='BPR', dataset='custom', config_dict=config_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrun_recbole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BPR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'custom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/quick_start/quick_start.py\u001b[0m in \u001b[0;36mrun_recbole\u001b[0;34m(model, dataset, config_file_list, config_dict, saved, queue)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# dataset filtering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/utils.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save_dataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_scratch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_from_scratch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m_from_scratch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_preset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_alias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m_load_data\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_inter_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         self.user_feat = self._load_user_or_item_feat(\n\u001b[1;32m    270\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"uid_field\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m_load_inter_feat\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {inter_feat_path} not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0minter_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_feat_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTERACTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             self.logger.debug(\n\u001b[1;32m    297\u001b[0m                 \u001b[0;34mf\"Interaction feature loaded successfully from [{inter_feat_path}].\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py\u001b[0m in \u001b[0;36m_load_feat\u001b[0;34m(self, filepath, source)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfield_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_separator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mftype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "# Configuration for running BPR Model\n",
    "config_dict = {\n",
    "    'model': 'BPR',\n",
    "    'dataset': 'custom',\n",
    "    'train_batch_size': 4096,\n",
    "    'eval_batch_size': 4096,\n",
    "    'epochs': 10,\n",
    "    'show_progress': True,\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],\n",
    "    'valid_metric': 'MRR@10',\n",
    "}\n",
    "\n",
    "# Run the BPR model with ml-100k dataset\n",
    "print(\"Training BPR with Custom (Medical) Dataset:\")\n",
    "#result = run_recbole(model='BPR', dataset='custom', config_dict=config_dict)\n",
    "run_recbole(model='BPR', dataset='custom')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
