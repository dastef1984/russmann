{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9e81f7",
   "metadata": {},
   "source": [
    "## List of General Recommendation Models in RecBole\n",
    "\n",
    "Below is a summary of the key general recommendation models available in the RecBole framework, designed primarily for handling implicit feedback data:\n",
    "\n",
    "- **Pop**: Simple popularity-based recommendation model.\n",
    "- **ItemKNN**: Traditional item-based collaborative filtering.\n",
    "- **BPR (Bayesian Personalized Ranking)**: Optimizes a pairwise ranking loss, ideal for datasets with implicit feedback.\n",
    "- **NeuMF (Neural Matrix Factorization)**: Combines classical matrix factorization with deep neural networks.\n",
    "- **ConvNCF (Convolutional Neural Collaborative Filtering)**: Integrates convolutional neural networks with matrix factorization.\n",
    "- **DMF (Deep Matrix Factorization)**: Uses deep learning techniques to enhance matrix factorization.\n",
    "- **FISM (Factored Item Similarity Models)**: A variant of matrix factorization focusing on item similarities.\n",
    "- **NAIS (Neural Attentive Item Similarity model)**: Applies attention mechanisms to item similarities in collaborative filtering.\n",
    "- **SpectralCF**: Leverages graph spectral theory for collaborative filtering.\n",
    "- **GCMC (Graph Convolutional Matrix Completion)**: Applies graph convolutional networks to matrix completion tasks.\n",
    "- **NGCF (Neural Graph Collaborative Filtering)**: Enhances collaborative filtering with graph neural networks.\n",
    "- **LightGCN**: Simplifies Graph Convolutional Networks by removing feature transformations and nonlinear activations.\n",
    "- **DGCF (Disentangled Graph Collaborative Filtering)**: Focuses on disentangling the latent factors in collaborative filtering.\n",
    "- **LINE**: Designed for large-scale information network embeddings.\n",
    "- **MultiVAE**, **MultiDAE**: Variational and denoising autoencoders for collaborative filtering.\n",
    "- **MacridVAE**: Variational autoencoder with a focus on disentangling user preferences.\n",
    "- **CDAE (Collaborative Denoising Auto-Encoder)**: Combines collaborative filtering with the denoising capabilities of autoencoders.\n",
    "- **ENMF (Efficient Neural Matrix Factorization)**: A more efficient take on neural matrix factorization.\n",
    "- **NNCF (Neural Network-based Collaborative Filtering)**: Utilizes neural networks for collaborative filtering.\n",
    "- **RaCT**, **RecVAE**: Advanced models using variational autoencoders for recommendation.\n",
    "- **EASE (Embarrassingly Shallow Autoencoders for Sparse Data)**: A straightforward linear autoencoder approach for collaborative filtering.\n",
    "- **SLIMElastic**: Sparse linear method enhanced with elastic net regularization.\n",
    "- **SGL (Self-supervised Graph Learning for recommendation)**: Integrates self-supervised learning with graph-based recommendation.\n",
    "- **ADMMSLIM**, **NCEPLRec**, **SimpleX**, **NCL (Neighborhood-based Collaborative Learning)**, **Random**, **DiffRec**, **LDiffRec**: Various models that integrate different techniques for general recommendation tasks.\n",
    "\n",
    "This comprehensive list includes a variety of models from simple to sophisticated, covering a wide range of techniques suitable for general recommendation scenarios, often based on implicit feedback.\n",
    "\n",
    "Source: https://recbole.io/docs/user_guide/model_intro.html#general-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bd509",
   "metadata": {},
   "source": [
    "## Grouped Recommendation Models in RecBole\n",
    "\n",
    "Below is an organized summary of key recommendation models in RecBole, grouped by their implementation approach. This categorization will help in selecting models based on specific use cases and characteristics of the dataset.\n",
    "\n",
    "### Collaborative Filtering Models\n",
    "These models make recommendations based on past interactions between users and items:\n",
    "\n",
    "- **ItemKNN**: Item-based nearest neighbors.\n",
    "- **BPR (Bayesian Personalized Ranking)**: Utilizes pairwise ranking loss, ideal for implicit feedback.\n",
    "- **NeuMF (Neural Matrix Factorization)**: Integrates deep learning with traditional matrix factorization.\n",
    "- **FISM (Factored Item Similarity Models)**: Focuses on item similarity using matrix factorization techniques.\n",
    "- **NAIS (Neural Attentive Item Similarity model)**: Applies attention mechanisms to enhance item similarity models.\n",
    "\n",
    "### Graph-Based Models\n",
    "Leveraging graph structures to represent complex relationships between items and users:\n",
    "\n",
    "- **SpectralCF**: Employs spectral graph theory in collaborative filtering.\n",
    "- **GCMC (Graph Convolutional Matrix Completion)**: Utilizes graph convolutional networks for matrix completion.\n",
    "- **NGCF (Neural Graph Collaborative Filtering)**: Incorporates graph neural networks to learn from user-item interactions.\n",
    "- **LightGCN**: Simplifies Graph Convolutional Networks by removing nonlinearities and feature transformation.\n",
    "- **DGCF (Disentangled Graph Collaborative Filtering)**: Disentangles latent factors in collaborative filtering using graphs.\n",
    "\n",
    "### Deep Learning Models\n",
    "Using neural networks to uncover patterns in user-item interactions:\n",
    "\n",
    "- **ConvNCF (Convolutional Neural Collaborative Filtering)**: Combines convolutional neural networks with matrix factorization.\n",
    "- **DMF (Deep Matrix Factorization)**: Enhances matrix factorization with deep learning techniques.\n",
    "- **NNCF (Neural Network-based Collaborative Filtering)**: General neural network approach for collaborative filtering.\n",
    "- **ENMF (Efficient Neural Matrix Factorization)**: A more efficient version of neural matrix factorization.\n",
    "\n",
    "### Autoencoder-Based Models\n",
    "Utilizing autoencoders to compress and learn from user-item interactions:\n",
    "\n",
    "- **MultiVAE**, **MultiDAE**: Variational and denoising autoencoders focused on collaborative filtering.\n",
    "- **MacridVAE**: Variational autoencoder designed to disentangle user preferences.\n",
    "- **RecVAE**: Advanced variational autoencoder for recommendation.\n",
    "- **EASE (Embarrassingly Shallow Autoencoders for Sparse Data)**: Simple linear autoencoder approach.\n",
    "\n",
    "### Hybrid Models\n",
    "Combining multiple techniques to utilize strengths from different areas:\n",
    "\n",
    "- **SLIMElastic**: Incorporates sparse linear methods with elastic net regularization.\n",
    "- **SGL (Self-supervised Graph Learning for recommendation)**: Integrates self-supervised learning with graph-based methods.\n",
    "- **ADMMSLIM**, **NCEPLRec**, **SimpleX**: Various methods that combine optimization techniques with collaborative filtering.\n",
    "- **Random**, **DiffRec**, **LDiffRec**: Models that incorporate differentiating strategies or random sampling.\n",
    "\n",
    "### Other Models\n",
    "Models that are categorized based on unique characteristics or simpler approaches:\n",
    "\n",
    "- **Pop**: Based purely on item popularity, involves no learning.\n",
    "- **LINE**: Designed for large-scale information network embeddings.\n",
    "\n",
    "This comprehensive list offers a structured way to explore various models based on their technical approach to handling recommendations, which can be particularly useful for academic or professional projects in recommender systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431702a",
   "metadata": {},
   "source": [
    "## ItemKNN with Explicit Feedback\n",
    "This configuration treats user ratings from the ML-100k dataset as explicit feedback. Here, the actual numerical ratings are used to compute similarities between items and to predict user preferences. This setup leverages the explicit ratings to rank items more accurately according to how users have rated them in the past. Unlike implicit feedback, which infers interactions, explicit feedback directly reflects user preferences, providing a clear indication of how much a user likes or dislikes an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399cf7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 15:49    INFO  ['/home/stef/.local/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/home/stef/.local/share/jupyter/runtime/kernel-ce844cad-8ee2-499f-8f1d-229165b49f0f.json']\n",
      "14 Apr 15:49    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /home/stef/.local/lib/python3.10/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "k = 20\n",
      "shrink = 0.0\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "similarity = cosine\n",
      "use_implicit = False\n",
      "eval_setting = RO_RS\n",
      "early_stop = 5\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/home/stef/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/stef/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "14 Apr 15:49    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "14 Apr 15:49    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Apr 15:49    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Apr 15:49    INFO  ItemKNN()\n",
      "Trainable parameters: 1\n",
      "14 Apr 15:49    INFO  FLOPs: 0.0\n",
      "Train     0:   0%|                                                           | 0/79 [00:00<?, ?it/s]:  70%|██████████████████████████████████               | 55/79 [00:00<00:00, 545.43it/s]: 100%|█████████████████████████████████████████████████| 79/79 [00:00<00:00, 471.32it/s]\n",
      "14 Apr 15:49    INFO  epoch 0 training [time: 0.17s, train loss: 0.0000]\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  41%|███████████████████                           | 195/472 [00:00<00:00, 1947.93it/s]:  83%|██████████████████████████████████████        | 390/472 [00:00<00:00, 1852.28it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1748.62it/s]\n",
      "14 Apr 15:49    INFO  epoch 0 evaluating [time: 0.28s, valid_score: 0.355300]\n",
      "14 Apr 15:49    INFO  valid result: \n",
      "recall@10 : 0.1884    mrr@10 : 0.3553    ndcg@10 : 0.2063    hit@10 : 0.7041    precision@10 : 0.1471\n",
      "14 Apr 15:49    INFO  Saving current: saved/ItemKNN-Apr-14-2024_15-49-22.pth\n",
      "14 Apr 15:49    INFO  Loading model structure and parameters from saved/ItemKNN-Apr-14-2024_15-49-22.pth\n",
      "Evaluate   :   0%|                                                          | 0/472 [00:00<?, ?it/s]:  33%|███████████████                               | 154/472 [00:00<00:00, 1534.28it/s]:  71%|████████████████████████████████▋             | 335/472 [00:00<00:00, 1692.65it/s]: 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1706.20it/s]\n",
      "14 Apr 15:49    INFO  The running environment of this training is as follows:\n",
      "+-------------+----------------+\n",
      "| Environment |     Usage      |\n",
      "+=============+================+\n",
      "| CPU         |    34.70 %     |\n",
      "+-------------+----------------+\n",
      "| GPU         |   0.0 / 0.0    |\n",
      "+-------------+----------------+\n",
      "| Memory      | 0.57 G/13.86 G |\n",
      "+-------------+----------------+\n",
      "14 Apr 15:49    INFO  best valid : OrderedDict([('recall@10', 0.1884), ('mrr@10', 0.3553), ('ndcg@10', 0.2063), ('hit@10', 0.7041), ('precision@10', 0.1471)])\n",
      "14 Apr 15:49    INFO  test result: OrderedDict([('recall@10', 0.2328), ('mrr@10', 0.4364), ('ndcg@10', 0.2637), ('hit@10', 0.7762), ('precision@10', 0.1852)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_valid_score': 0.3553,\n",
       " 'valid_score_bigger': True,\n",
       " 'best_valid_result': OrderedDict([('recall@10', 0.1884),\n",
       "              ('mrr@10', 0.3553),\n",
       "              ('ndcg@10', 0.2063),\n",
       "              ('hit@10', 0.7041),\n",
       "              ('precision@10', 0.1471)]),\n",
       " 'test_result': OrderedDict([('recall@10', 0.2328),\n",
       "              ('mrr@10', 0.4364),\n",
       "              ('ndcg@10', 0.2637),\n",
       "              ('hit@10', 0.7762),\n",
       "              ('precision@10', 0.1852)])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration for running ItemKNN Model with Explicit Feedback - Ranking Metrics\n",
    "config_dict_ranking = {\n",
    "    'model': 'ItemKNN',\n",
    "    'dataset': 'ml-100k',\n",
    "    'similarity': 'cosine',\n",
    "    'k': 20,\n",
    "    'use_implicit': False,\n",
    "    'eval_setting': 'RO_RS',\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],  # Focus on ranking-based metrics\n",
    "    'valid_metric': 'MRR@10',\n",
    "    'topk': 10,\n",
    "    'gpu_id': 0,\n",
    "    'early_stop': 5,\n",
    "}\n",
    "\n",
    "# Run the model for ranking metrics\n",
    "run_recbole(model='ItemKNN', dataset='ml-100k', config_dict=config_dict_ranking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9244ead6",
   "metadata": {},
   "source": [
    "## ItemKNN Model with Implicit Feedback Conversion\n",
    "\n",
    "This process involves converting the explicit ratings from the MovieLens 100K dataset into a binary format for implicit feedback analysis. Ratings above a threshold of 3.5 are considered positive interactions (indicative of a user liking an item), while all others are discarded. This binary dataset is then utilized to train the ItemKNN model within RecBole, focusing on uncovering latent patterns in user-item interactions without relying on explicit numerical ratings. This approach emphasizes whether an interaction occurred, rather than its magnitude, aligning with typical use cases for implicit feedback where only user actions (clicks, views) are tracked.\n",
    "\n",
    "### Implementation Details\n",
    "- **Data Conversion**: Ratings are transformed to a binary scale indicating presence or absence of interaction, refining the dataset to only include instances of positive feedback (feedback greater than 3.5 is positive).\n",
    "- **Model Configuration**: The ItemKNN model is configured to handle this implicit dataset by calculating item similarities based on the presence of user interactions. This setup helps in predicting which items a user might interact with, based on similar items they have interacted with in the past.\n",
    "- **Execution and Evaluation**: The model is run using RecBole's framework, evaluating its performance on metrics like Recall, MRR, and NDCG, which are crucial for assessing the effectiveness of recommendations based on implicit feedback.\n",
    "\n",
    "This methodology leverages the strengths of the ItemKNN algorithm in a scenario typical for systems where explicit ratings are not available, making it highly relevant for applications like e-commerce and media streaming platforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d31432ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>1</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>1</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>1</td>\n",
       "      <td>879781125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>876042340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>122</td>\n",
       "      <td>387</td>\n",
       "      <td>1</td>\n",
       "      <td>879270459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>421</td>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>892241344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>495</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>888637503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>806</td>\n",
       "      <td>421</td>\n",
       "      <td>1</td>\n",
       "      <td>882388897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>676</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>892685437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "5          298      474       1  884182806\n",
       "7          253      465       1  891628467\n",
       "11         286     1014       1  879781125\n",
       "12         200      222       1  876042340\n",
       "16         122      387       1  879270459\n",
       "...        ...      ...     ...        ...\n",
       "99988      421      498       1  892241344\n",
       "99989      495     1091       1  888637503\n",
       "99990      806      421       1  882388897\n",
       "99991      676      538       1  892685437\n",
       "99996      716      204       1  879795543\n",
       "\n",
       "[55375 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Define a threshold\n",
    "threshold = 3.5\n",
    "\n",
    "# Convert ratings to binary\n",
    "data['rating'] = (data['rating'] > threshold).astype(int)\n",
    "\n",
    "# Filter out non-interactions\n",
    "data = data[data['rating'] == 1]\n",
    "\n",
    "data.to_csv('ml100k_implicit.csv', index=False, sep='\\t')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d127b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'item_id', 'rating', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your current data\n",
    "data = pd.read_csv('dataset/implicit_ml-100k/implicit_ml-100k.inter', delimiter='\\t')\n",
    "\n",
    "# Assuming your data includes the columns: user_id, item_id, rating, and optionally timestamp\n",
    "# Check what columns are actually in your data\n",
    "print(data.columns)\n",
    "\n",
    "# Save it back with the correct header\n",
    "# Make sure to include all columns that exist in your data\n",
    "data.to_csv('dataset/implicit_ml-100k/implicit_ml-100k.inter', sep='\\t', index=False,\n",
    "            header=['user_id:token', 'item_id:token', 'rating:float', 'timestamp:float'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcd8151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Apr 16:51    INFO  ['/home/stef/.local/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/home/stef/.local/share/jupyter/runtime/kernel-ce844cad-8ee2-499f-8f1d-229165b49f0f.json']\n",
      "14 Apr 16:51    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /home/stef/russmann/dataset/implicit_ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "k = 20\n",
      "shrink = 0.0\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.TRADITIONAL\n",
      "similarity = cosine\n",
      "eval_setting = RO_RS\n",
      "early_stop = 5\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/home/stef/.local/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Apr 16:51    INFO  implicit_ml-100k\n",
      "The number of users: 943\n",
      "Average actions of users: 58.78450106157113\n",
      "The number of items: 1448\n",
      "Average actions of items: 38.26883206634416\n",
      "The number of inters: 55375\n",
      "The sparsity of the dataset: 95.944601981451%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Apr 16:51    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Apr 16:51    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Apr 16:51    INFO  ItemKNN()\n",
      "Trainable parameters: 1\n",
      "14 Apr 16:51    INFO  FLOPs: 0.0\n",
      "Train     0:   0%|                                                           | 0/45 [00:00<?, ?it/s]: 100%|█████████████████████████████████████████████████| 45/45 [00:00<00:00, 693.32it/s]\n",
      "14 Apr 16:51    INFO  epoch 0 training [time: 0.08s, train loss: 0.0000]\n",
      "Evaluate   :   0%|                                                          | 0/471 [00:00<?, ?it/s]:  34%|███████████████▊                              | 162/471 [00:00<00:00, 1610.74it/s]:  77%|███████████████████████████████████▋          | 365/471 [00:00<00:00, 1850.92it/s]: 100%|██████████████████████████████████████████████| 471/471 [00:00<00:00, 1863.02it/s]\n",
      "14 Apr 16:51    INFO  epoch 0 evaluating [time: 0.27s, valid_score: 0.279400]\n",
      "14 Apr 16:51    INFO  valid result: \n",
      "recall@10 : 0.2241    mrr@10 : 0.2794    ndcg@10 : 0.1797    hit@10 : 0.5669    precision@10 : 0.0923\n",
      "14 Apr 16:51    INFO  Saving current: saved/ItemKNN-Apr-14-2024_16-51-46.pth\n",
      "14 Apr 16:51    INFO  Loading model structure and parameters from saved/ItemKNN-Apr-14-2024_16-51-46.pth\n",
      "Evaluate   :   0%|                                                          | 0/471 [00:00<?, ?it/s]:  40%|██████████████████▍                           | 189/471 [00:00<00:00, 1884.66it/s]:  80%|████████████████████████████████████▉         | 378/471 [00:00<00:00, 1814.36it/s]: 100%|██████████████████████████████████████████████| 471/471 [00:00<00:00, 1811.74it/s]\n",
      "14 Apr 16:51    INFO  The running environment of this training is as follows:\n",
      "+-------------+----------------+\n",
      "| Environment |     Usage      |\n",
      "+=============+================+\n",
      "| CPU         |    39.30 %     |\n",
      "+-------------+----------------+\n",
      "| GPU         |   0.0 / 0.0    |\n",
      "+-------------+----------------+\n",
      "| Memory      | 0.58 G/13.86 G |\n",
      "+-------------+----------------+\n",
      "14 Apr 16:51    INFO  best valid : OrderedDict([('recall@10', 0.2241), ('mrr@10', 0.2794), ('ndcg@10', 0.1797), ('hit@10', 0.5669), ('precision@10', 0.0923)])\n",
      "14 Apr 16:51    INFO  test result: OrderedDict([('recall@10', 0.221), ('mrr@10', 0.2908), ('ndcg@10', 0.1877), ('hit@10', 0.569), ('precision@10', 0.0993)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_valid_score': 0.2794,\n",
       " 'valid_score_bigger': True,\n",
       " 'best_valid_result': OrderedDict([('recall@10', 0.2241),\n",
       "              ('mrr@10', 0.2794),\n",
       "              ('ndcg@10', 0.1797),\n",
       "              ('hit@10', 0.5669),\n",
       "              ('precision@10', 0.0923)]),\n",
       " 'test_result': OrderedDict([('recall@10', 0.221),\n",
       "              ('mrr@10', 0.2908),\n",
       "              ('ndcg@10', 0.1877),\n",
       "              ('hit@10', 0.569),\n",
       "              ('precision@10', 0.0993)])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "# Configuration for running ItemKNN Model with Implicit Feedback\n",
    "config_dict_implicit = {\n",
    "    'model': 'ItemKNN',\n",
    "    'dataset': 'implicit_ml-100k',\n",
    "    'data_path': '/home/stef/russmann/dataset/',  # Adjust this path as necessary\n",
    "    'similarity': 'cosine',\n",
    "    'k': 20,\n",
    "    'eval_setting': 'RO_RS',\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'],\n",
    "    'valid_metric': 'MRR@10',\n",
    "    'topk': 10,\n",
    "    'early_stop': 5,\n",
    "    'gpu_id': 0,\n",
    "}\n",
    "\n",
    "# Run the model\n",
    "run_recbole(model='ItemKNN', dataset='implicit_ml-100k', config_dict=config_dict_implicit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
