{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHO5P7e5VEmceGNsRZvWiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dastef1984/russmann/blob/master/mapping_debugging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Discrepancy between Custom and RecBole NDCG Calculation\n",
        "\n",
        "- **Challenge**: My custom implementation of the NDCG metric produces significantly different results from RecBole’s built-in NDCG calculation, despite using similar formulas for Discounted Cumulative Gain (DCG) and Ideal DCG (IDCG).\n",
        "- **Goal**: To determine why my custom NDCG calculation does not match RecBole’s NDCG results.\n",
        "- **What I’ve Tried**:\n",
        "    - Implemented a custom NDCG calculation using the formula for DCG and IDCG:\n"
      ],
      "metadata": {
        "id": "pb5CV_nmftqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_ndcg_at_k(predictions, ground_truth, k=10):\n",
        "    def dcg_at_k(recommended_items, relevant_items, k):\n",
        "        dcg = 0.0\n",
        "        for i in range(min(k, len(recommended_items))):\n",
        "            if recommended_items[i] in relevant_items:\n",
        "                dcg += 1 / np.log2(i + 2)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(relevant_items, k):\n",
        "        idcg = 0.0\n",
        "        for i in range(min(k, len(relevant_items))):\n",
        "            idcg += 1 / np.log2(i + 2)\n",
        "        return idcg\n",
        "\n",
        "    total_ndcg = 0.0\n",
        "    num_users = len(predictions)\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        recommended_items = predictions[user_idx]\n",
        "        relevant_items = ground_truth[user_idx]\n",
        "\n",
        "        # Calculate DCG@K\n",
        "        dcg = dcg_at_k(recommended_items, relevant_items, k)\n",
        "        # Calculate IDCG@K\n",
        "        idcg = idcg_at_k(relevant_items, k)\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / num_users\n"
      ],
      "metadata": {
        "id": "iG7BVqiCf2qf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - I compared it to RecBole’s simulated NDCG calculation based on their source code.\n",
        "   - **Result**: My custom NDCG gave results like 0.012, while RecBole's NDCG gave significantly higher values (0.19 or higher). I am unsure where the discrepancy comes from.\n",
        "\n",
        "- **Questions for Supervisor**:\n",
        "   - Could the mapping of internal vs. external IDs (from RecBole’s dataset) be affecting my NDCG calculation? I’ve already ensured that both IDs map correctly when converting back and forth, but the results still differ.\n",
        "   - Should I try to align my DCG/IDCG calculation approach to RecBole’s more closely, e.g., by following RecBole’s binary relevance indexing system?\n"
      ],
      "metadata": {
        "id": "aYvbJuqpf7Er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - **Result**: Unsure if this impacts the way RecBole calculates relevance for metrics like NDCG.\n",
        "\n",
        "- **Questions**:\n",
        "   - Should I inspect RecBole’s entire preprocessing pipeline to understand how it handles relevance scores?\n",
        "   - Would aligning my preprocessing steps with RecBole’s possibly eliminate the discrepancy between custom and RecBole-calculated NDCG?\n"
      ],
      "metadata": {
        "id": "CE7q4WKRf7yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing in RecBole\n",
        "\n",
        "- **Challenge**: I suspect that RecBole's preprocessing steps might affect how relevance is handled during NDCG calculations.\n",
        "- **Goal**: Understand and compare RecBole’s preprocessing steps with my own approach.\n",
        "- **What I’ve Tried**:\n",
        "   - Loaded the dataset and checked the output of the internal features after preprocessing:\n"
      ],
      "metadata": {
        "id": "byZNASn8g2Jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating RecBole’s NDCG Calculation\n",
        "\n",
        "- **Challenge**: My attempt to simulate RecBole’s NDCG calculation yielded only approximated results.\n",
        "- **Goal**: Ensure my simulated NDCG calculation matches RecBole’s implementation exactly."
      ],
      "metadata": {
        "id": "7TgHhdz4hvUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - The results are similar but still not exactly the same as RecBole’s output.\n",
        "\n",
        "- **Questions**:\n",
        "   - Should I continue refining this, or would it make sense to focus on why my original custom implementation doesn’t match RecBole’s?\n"
      ],
      "metadata": {
        "id": "Kx2Cm3JAh8FG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2CpLFENqR4",
        "outputId": "652e39c7-ea29-4aee-c6e5-ab2f5de16df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recbole\n",
            "  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (4.66.5)\n",
            "Collecting colorlog==4.7.2 (from recbole)\n",
            "  Downloading colorlog-4.7.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting colorama==0.4.4 (from recbole)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.5.2)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (6.0.2)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.17.0)\n",
            "Collecting thop>=0.1.1.post2207130030 (from recbole)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from recbole) (0.9.0)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (5.24.1)\n",
            "Collecting texttable>=0.9.0 (from recbole)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (24.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->recbole) (1.3.0)\n",
            "Downloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: texttable, colorlog, colorama, thop, recbole\n",
            "Successfully installed colorama-0.4.4 colorlog-4.7.2 recbole-1.2.0 texttable-1.7.0 thop-0.1.1.post2209072238\n",
            "Collecting ray\n",
            "  Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl (65.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.37.0\n",
            "Collecting kmeans-pytorch\n",
            "  Downloading kmeans_pytorch-0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install recbole\n",
        "!pip install ray\n",
        "!pip install kmeans-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recbole.quick_start import run_recbole\n",
        "import os\n",
        "\n",
        "# Configuration for training BPR model on ml100k\n",
        "dataset_name = 'ml-100k'\n",
        "checkpoint_dir = './saved_models/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Configuration dictionary\n",
        "config_dict = {\n",
        "    'model': 'BPR',\n",
        "    'dataset': dataset_name,\n",
        "    'data_path': './dataset/',\n",
        "    'epochs': 10,\n",
        "    'topk': 10,\n",
        "    'metrics': ['ndcg', 'mrr'],   # Metrics for comparison\n",
        "    'checkpoint_dir': checkpoint_dir,\n",
        "    'save_model': True,\n",
        "    'valid_metric': 'ndcg@10',\n",
        "}\n",
        "\n",
        "# Train the BPR model\n",
        "result = run_recbole(config_dict=config_dict)\n",
        "\n",
        "# Output the RecBole evaluation results\n",
        "print(f\"RecBole Validation Result: {result['best_valid_result']}\")\n",
        "print(f\"RecBole Test Result: {result['test_result']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-cm2t6nNxLB",
        "outputId": "1d4f437c-02c9-4753-b55d-1ffea6188ebf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-56f2eed3-9eac-4f4c-b361-89b72447a36d.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 91.40it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1254.43it/s]\n",
            "Train     1: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 112.37it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1428.43it/s]\n",
            "Train     2: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 107.00it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1557.76it/s]\n",
            "Train     3: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 98.89it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1557.48it/s]\n",
            "Train     4: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 108.24it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1228.16it/s]\n",
            "Train     5: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 109.80it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1411.03it/s]\n",
            "Train     6: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 106.99it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1569.42it/s]\n",
            "Train     7: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 99.38it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1497.73it/s]\n",
            "Train     8: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 113.67it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1299.55it/s]\n",
            "Train     9: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 115.96it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1281.47it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1431.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecBole Validation Result: OrderedDict([('ndcg@10', 0.1601), ('mrr@10', 0.2991)])\n",
            "RecBole Test Result: OrderedDict([('ndcg@10', 0.1911), ('mrr@10', 0.3565)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recbole.quick_start import load_data_and_model\n",
        "\n",
        "# Load the trained BPR model and dataset\n",
        "model_file = './saved_models/BPR.pth'\n",
        "config, model, dataset, _, test_dataloader, _ = load_data_and_model(model_file)\n",
        "\n",
        "# Function to get top-k recommendations for users\n",
        "import torch\n",
        "\n",
        "def get_topk_recommendations(model, dataloader, topk=10):\n",
        "    model.eval()\n",
        "    topk_recommendations = []\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]\n",
        "        scores = model.full_sort_predict(interaction)\n",
        "        topk_items = torch.topk(scores, k=topk, dim=-1).indices\n",
        "        topk_recommendations.append(topk_items.cpu().numpy())\n",
        "    return topk_recommendations\n",
        "\n",
        "bpr_topk_recs = get_topk_recommendations(model, test_dataloader, topk=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkTOVeZgR-FP",
        "outputId": "3477ca9e-3689-4fbe-b7c4-3f7d5ae965c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ground_truth(dataset):\n",
        "    ground_truth = []\n",
        "    for i in range(len(dataset.inter_feat)):\n",
        "        ground_truth.append(dataset.inter_feat['item_id'][i])  # No conversion needed, already internal ID\n",
        "    return ground_truth\n",
        "\n",
        "bpr_ground_truth = extract_ground_truth(dataset)"
      ],
      "metadata": {
        "id": "dzDknTWnUIct"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Custom NDCG@10 calculation\n",
        "def calculate_ndcg_at_k(topk_recs, ground_truth, k=10):\n",
        "    def dcg_at_k(recommended_items, relevant_items, k):\n",
        "        dcg = 0.0\n",
        "        for i in range(min(k, len(recommended_items))):\n",
        "            if recommended_items[i] in relevant_items:\n",
        "                dcg += 1 / np.log2(i + 2)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(relevant_items, k):\n",
        "        idcg = 0.0\n",
        "        for i in range(min(k, len(relevant_items))):\n",
        "            idcg += 1 / np.log2(i + 2)\n",
        "        return idcg\n",
        "\n",
        "    total_ndcg = 0.0\n",
        "    num_users = len(topk_recs)\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        recommended_items = topk_recs[user_idx]\n",
        "        relevant_items = [ground_truth[user_idx]]\n",
        "\n",
        "        # Calculate DCG@K\n",
        "        dcg = dcg_at_k(recommended_items, relevant_items, k)\n",
        "        # Calculate IDCG@K\n",
        "        idcg = idcg_at_k(relevant_items, k)\n",
        "\n",
        "        if idcg == 0:\n",
        "            ndcg = 0.0\n",
        "        else:\n",
        "            ndcg = dcg / idcg\n",
        "\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / num_users\n",
        "\n",
        "# Compare NDCG@10\n",
        "custom_ndcg = calculate_ndcg_at_k(bpr_topk_recs, bpr_ground_truth, k=10)\n",
        "print(f\"Custom NDCG@10: {custom_ndcg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwnbfE3UKmD",
        "outputId": "3fb61dfe-430f-4159-b2be-b9ccadde6a10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom NDCG@10: 0.01211335827200395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Custom NDCG Calculation Function\n",
        "def calculate_ndcg_at_k(topk_recs, ground_truth, k=10):\n",
        "    def dcg_at_k(recommended_items, relevant_items, k):\n",
        "        dcg = 0.0\n",
        "        for i in range(min(k, len(recommended_items))):\n",
        "            if recommended_items[i] in relevant_items:\n",
        "                dcg += 1 / np.log2(i + 2)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(relevant_items, k):\n",
        "        idcg = 0.0\n",
        "        for i in range(min(k, len(relevant_items))):\n",
        "            idcg += 1 / np.log2(i + 2)\n",
        "        return idcg\n",
        "\n",
        "    total_ndcg = 0.0\n",
        "    num_users = len(topk_recs)\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        recommended_items = topk_recs[user_idx]\n",
        "        relevant_items = ground_truth[user_idx]\n",
        "\n",
        "        # Ensure relevant_items is a list\n",
        "        if isinstance(relevant_items, int):\n",
        "            relevant_items = [relevant_items]  # Convert int to a list for comparison\n",
        "\n",
        "        # Calculate DCG@K for this user\n",
        "        dcg = dcg_at_k(recommended_items, relevant_items, k)\n",
        "        # Calculate IDCG@K for this user\n",
        "        idcg = idcg_at_k(relevant_items, k)\n",
        "\n",
        "        if idcg == 0:\n",
        "            ndcg = 0.0\n",
        "        else:\n",
        "            ndcg = dcg / idcg\n",
        "\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / num_users\n",
        "\n",
        "\n",
        "# Extract ground truth as lists of relevant items for each user\n",
        "def extract_ground_truth_from_dataset(dataset, test=True):\n",
        "    ground_truth = []\n",
        "    data = dataset.inter_feat if test else dataset.train_data\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        item_id = data['item_id'][i]\n",
        "        ground_truth.append([item_id])  # Ensure ground truth is a list of relevant items for each user\n",
        "\n",
        "    return ground_truth\n",
        "\n",
        "# Extract the ground truth interactions from the test dataset for comparison\n",
        "bpr_ground_truth = extract_ground_truth_from_dataset(bpr_dataset, test=True)\n",
        "\n",
        "# Step 6: Compare the custom NDCG with RecBole's NDCG\n",
        "print(\"\\nCalculating Custom NDCG:\")\n",
        "custom_ndcg = calculate_ndcg_at_k(bpr_topk_recs, bpr_ground_truth, k=10)\n",
        "print(f\"Custom NDCG@10: {custom_ndcg}\")\n",
        "\n",
        "print(f\"\\nRecBole NDCG@10: {recbole_result['test_result']['ndcg@10']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "g2s1PJQ4VRII",
        "outputId": "6aad80bd-84e3-4bd7-b1bc-7ee0b7721695"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bpr_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-97fb134e2327>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Extract the ground truth interactions from the test dataset for comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mbpr_ground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_ground_truth_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbpr_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Step 6: Compare the custom NDCG with RecBole's NDCG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bpr_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from recbole.config import Config\n",
        "from recbole.data import create_dataset, data_preparation\n",
        "from recbole.data.interaction import Interaction\n",
        "from recbole.model.general_recommender.bpr import BPR\n",
        "\n",
        "def convert_tokens_to_ids(dataset, field, tokens):\n",
        "    \"\"\"Convert external tokens to internal ids.\"\"\"\n",
        "    if isinstance(tokens, str):\n",
        "        return dataset.token2id(field, tokens)\n",
        "    elif isinstance(tokens, (list, np.ndarray)):\n",
        "        return np.array([dataset.token2id(field, token) for token in tokens])\n",
        "    else:\n",
        "        raise TypeError(f\"The type of tokens [{tokens}] is not supported\")\n",
        "\n",
        "def convert_ids_to_tokens(dataset, field, ids):\n",
        "    \"\"\"Convert internal ids to external tokens.\"\"\"\n",
        "    if isinstance(ids, (list, np.ndarray, torch.Tensor)):\n",
        "        return dataset.id2token(field, ids)\n",
        "    else:\n",
        "        raise TypeError(f\"The type of ids [{ids}] is not supported\")\n",
        "\n",
        "# Inline configuration dictionary\n",
        "config_dict = {\n",
        "    'model': 'BPR',\n",
        "    'dataset': 'ml-100k',\n",
        "    'data_path': './dataset/ml-100k/',\n",
        "    'epochs': 10,\n",
        "    'topk': 10,\n",
        "    'metrics': ['ndcg', 'mrr'],\n",
        "    'train_batch_size': 512,\n",
        "    'eval_batch_size': 512,\n",
        "    'valid_metric': 'ndcg@10',\n",
        "    'save_model': True,\n",
        "    'checkpoint_dir': './saved_models/',\n",
        "}\n",
        "\n",
        "# Load model, dataset and prepare data without external config file\n",
        "config = Config(config_dict=config_dict)\n",
        "dataset = create_dataset(config)\n",
        "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
        "\n",
        "# Load model\n",
        "model = BPR(config, dataset)\n",
        "checkpoint_path = './saved_models/BPR.pth'  # Make sure to adjust the path\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Example external user and item IDs\n",
        "user_ids = ['1', '2', '3']  # Use actual user IDs from the dataset\n",
        "item_id_lists = [['50', '172', '300'], ['10', '20'], ['100', '200']]\n",
        "\n",
        "# Convert external tokens to internal IDs\n",
        "user_ids_internal = convert_tokens_to_ids(dataset, 'user_id', user_ids)\n",
        "item_id_lists_internal = [convert_tokens_to_ids(dataset, 'item_id', item_list) for item_list in item_id_lists]\n",
        "\n",
        "# Prepare the input for interaction with padding\n",
        "max_list_size = 50\n",
        "padded_item_id_lists = np.zeros((len(user_ids), max_list_size), dtype=int)\n",
        "item_lengths = []\n",
        "\n",
        "for i, item_list in enumerate(item_id_lists_internal):\n",
        "    item_lengths.append(len(item_list))\n",
        "    padded_item_id_lists[i, :len(item_list)] = item_list\n",
        "\n",
        "# Create interaction for model input\n",
        "input_inter = Interaction({\n",
        "    'user_id': torch.tensor(user_ids_internal),\n",
        "    'item_id_list': torch.tensor(padded_item_id_lists),\n",
        "    'item_length': torch.tensor(item_lengths),\n",
        "})\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    scores = model.full_sort_predict(input_inter)\n",
        "\n",
        "# Convert internal IDs back to external item tokens\n",
        "scores = scores.numpy()\n",
        "item_ids_external = np.arange(scores.shape[1])\n",
        "item_ids_external = convert_ids_to_tokens(dataset, 'item_id', item_ids_external)\n",
        "\n",
        "# Display the top-10 predicted items for each user\n",
        "for i, user_id in enumerate(user_ids):\n",
        "    top_10_indices = np.argsort(scores[i])[::-1][:10]\n",
        "    top_10_items = item_ids_external[top_10_indices]\n",
        "    top_10_scores = scores[i][top_10_indices]\n",
        "    print(f\"User ID: {user_id}\")\n",
        "    print(\"Top 10 predicted items:\")\n",
        "    for item, score in zip(top_10_items, top_10_scores):\n",
        "        print(f\"Item ID: {item}, Score: {score:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "4mgDNUhuX7gN",
        "outputId": "89860e67-4511-4646-e2e3-6afedddd6b66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-56f2eed3-9eac-4f4c-b361-89b72447a36d.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "<ipython-input-12-515a53437133>:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-515a53437133>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Convert internal IDs back to external item tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mitem_ids_external\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mitem_ids_external\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ids_external\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    scores = model.full_sort_predict(input_inter)\n",
        "    print(\"Shape of scores:\", scores.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo0LaaoRZfa2",
        "outputId": "09052937-906f-44ad-8d63-741ab084603f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of scores: torch.Size([5049])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For a single user, `scores` is 1D\n",
        "if len(scores.shape) == 1:\n",
        "    item_ids_external = np.arange(scores.shape[0])\n",
        "else:\n",
        "    item_ids_external = np.arange(scores.shape[1])  # For multiple users\n"
      ],
      "metadata": {
        "id": "j0HNAfqdZrxA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total number of items in the dataset\n",
        "num_items_in_dataset = dataset.item_num\n",
        "\n",
        "# Adjust the top-k recommendations to handle out-of-bounds indices\n",
        "with torch.no_grad():\n",
        "    scores = model.full_sort_predict(input_inter)\n",
        "    print(\"Shape of scores:\", scores.shape)\n",
        "\n",
        "# Convert internal IDs back to external item tokens\n",
        "if len(scores.shape) == 1:  # Single user\n",
        "    item_ids_external = np.arange(min(scores.shape[0], num_items_in_dataset))\n",
        "else:  # Multiple users\n",
        "    item_ids_external = np.arange(min(scores.shape[1], num_items_in_dataset))\n",
        "\n",
        "# Convert the internal IDs to tokens only for valid IDs\n",
        "item_ids_external = convert_ids_to_tokens(dataset, 'item_id', item_ids_external)\n",
        "\n",
        "# Process the top-k items, ensuring we stay within the valid range of item IDs\n",
        "if len(scores.shape) == 1:  # Single user\n",
        "    top_10_indices = np.argsort(scores)[:10]\n",
        "    top_10_indices = top_10_indices[top_10_indices < num_items_in_dataset]  # Filter out-of-bounds indices\n",
        "    top_10_items = item_ids_external[top_10_indices]\n",
        "    top_10_scores = scores[top_10_indices]\n",
        "\n",
        "    print(\"Top 10 predicted items for the single user:\")\n",
        "    for item, score in zip(top_10_items, top_10_scores):\n",
        "        print(f\"Item ID: {item}, Score: {score:.4f}\")\n",
        "else:\n",
        "    # Loop through each user's predictions if multiple users\n",
        "    for i in range(scores.shape[0]):\n",
        "        top_10_indices = np.argsort(scores[i])[:10]\n",
        "        top_10_indices = top_10_indices[top_10_indices < num_items_in_dataset]  # Filter out-of-bounds indices\n",
        "        top_10_items = item_ids_external[top_10_indices]\n",
        "        top_10_scores = scores[i][top_10_indices]\n",
        "\n",
        "        print(f\"Top 10 predicted items for user {i}:\")\n",
        "        for item, score in zip(top_10_items, top_10_scores):\n",
        "            print(f\"Item ID: {item}, Score: {score:.4f}\")\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOw9WNONZt9h",
        "outputId": "9e5ba19d-31cc-405b-da2a-3df4adf9795c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of scores: torch.Size([5049])\n",
            "Top 10 predicted items for the single user:\n",
            "Item ID: 1660, Score: -2.3586\n",
            "Item ID: 1626, Score: -2.3237\n",
            "Item ID: 1347, Score: -2.3016\n",
            "Item ID: 1669, Score: -2.2747\n",
            "Item ID: 1666, Score: -2.2684\n",
            "Item ID: 1676, Score: -2.2617\n",
            "Item ID: 1616, Score: -2.2590\n",
            "Item ID: 1678, Score: -2.2337\n",
            "Item ID: 1364, Score: -2.2307\n",
            "Item ID: 1307, Score: -2.2251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Custom NDCG calculation\n",
        "def calculate_ndcg_at_k(topk_recs, ground_truth, k=10):\n",
        "    def dcg_at_k(recommended_items, relevant_items, k):\n",
        "        dcg = 0.0\n",
        "        for i in range(min(k, len(recommended_items))):\n",
        "            # Check if each element is iterable or scalar\n",
        "            if isinstance(recommended_items[i], (list, np.ndarray)):\n",
        "                if any(item in relevant_items for item in recommended_items[i]):\n",
        "                    dcg += 1 / np.log2(i + 2)\n",
        "            else:\n",
        "                if recommended_items[i] in relevant_items:\n",
        "                    dcg += 1 / np.log2(i + 2)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(relevant_items, k):\n",
        "        idcg = 0.0\n",
        "        for i in range(min(k, len(relevant_items))):\n",
        "            idcg += 1 / np.log2(i + 2)\n",
        "        return idcg\n",
        "\n",
        "    total_ndcg = 0.0\n",
        "    num_users = len(topk_recs)\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        recommended_items = topk_recs[user_idx]\n",
        "        relevant_items = ground_truth[user_idx]\n",
        "\n",
        "        # Ensure both recommended_items and relevant_items are lists\n",
        "        if isinstance(recommended_items, torch.Tensor):\n",
        "            recommended_items = recommended_items.tolist()\n",
        "        if isinstance(relevant_items, torch.Tensor):\n",
        "            relevant_items = relevant_items.tolist()\n",
        "        if isinstance(recommended_items, int):  # Convert a single integer to a list\n",
        "            recommended_items = [recommended_items]\n",
        "        if isinstance(relevant_items, int):\n",
        "            relevant_items = [relevant_items]\n",
        "\n",
        "        # Calculate DCG@K for this user\n",
        "        dcg = dcg_at_k(recommended_items, relevant_items, k)\n",
        "        # Calculate IDCG@K for this user\n",
        "        idcg = idcg_at_k(relevant_items, k)\n",
        "\n",
        "        if idcg == 0:\n",
        "            ndcg = 0.0\n",
        "        else:\n",
        "            ndcg = dcg / idcg\n",
        "\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / num_users\n",
        "\n",
        "# Assuming bpr_topk_recs and bpr_ground_truth have already been extracted\n",
        "# Step 3: Calculate Custom NDCG\n",
        "custom_ndcg = calculate_ndcg_at_k(bpr_topk_recs, bpr_ground_truth, k=10)\n",
        "\n",
        "# Output the custom NDCG@10\n",
        "print(f\"Custom NDCG@10: {custom_ndcg}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGswVCNBafGh",
        "outputId": "949b0b96-287f-460d-b53f-e80f7b9ddc70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom NDCG@10: 0.01211335827200395\n"
          ]
        }
      ]
    }
  ]
}