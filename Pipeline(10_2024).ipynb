{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXVcKLyWD5N4ia0mnAu9y1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dastef1984/russmann/blob/master/Pipeline(10_2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTx7jOyUR3qQ",
        "outputId": "42a082e5-95e8-447a-a89d-f9e59549eba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recbole\n",
            "  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (4.66.5)\n",
            "Collecting colorlog==4.7.2 (from recbole)\n",
            "  Downloading colorlog-4.7.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting colorama==0.4.4 (from recbole)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.5.2)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (6.0.2)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.17.0)\n",
            "Collecting thop>=0.1.1.post2207130030 (from recbole)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from recbole) (0.9.0)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (5.24.1)\n",
            "Collecting texttable>=0.9.0 (from recbole)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (24.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->recbole) (1.3.0)\n",
            "Downloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: texttable, colorlog, colorama, thop, recbole\n",
            "Successfully installed colorama-0.4.4 colorlog-4.7.2 recbole-1.2.0 texttable-1.7.0 thop-0.1.1.post2209072238\n",
            "Collecting ray\n",
            "  Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl (65.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.37.0\n",
            "Collecting kmeans-pytorch\n",
            "  Downloading kmeans_pytorch-0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install recbole\n",
        "!pip install ray\n",
        "!pip install kmeans-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from recbole.quick_start import run_recbole\n",
        "\n",
        "# Path where models will be saved\n",
        "checkpoint_dir = './saved_models/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Dataset and Model Configuration\n",
        "dataset_name = 'ml-100k'\n",
        "data_path = 'dataset/'\n",
        "\n",
        "# Define metrics for evaluation (only NDCG for now)\n",
        "metrics = ['MRR']\n",
        "\n",
        "# Check if the dataset path exists\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"Dataset path {data_path} does not exist. Please ensure the dataset is available.\")\n",
        "else:\n",
        "    print(f\"Dataset {dataset_name} is ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZjoFukR9nf",
        "outputId": "432008e2-11dd-45c5-962a-890e25f0b421"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path dataset/ does not exist. Please ensure the dataset is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Function to get configuration dictionary for each model\n",
        "def get_config(model_name):\n",
        "    config_dict = {\n",
        "        'model': model_name,\n",
        "        'dataset': dataset_name,\n",
        "        'data_path': data_path,\n",
        "        'epochs': 10,    # Modify if you want to adjust training duration\n",
        "        'topk': 10,      # We'll evaluate Top-K items (for MRR)\n",
        "        'metrics': metrics,\n",
        "        'checkpoint_dir': checkpoint_dir,  # Define checkpoint directory\n",
        "        'save_model': True,  # Ensure the model is saved\n",
        "    }\n",
        "    return config_dict\n",
        "\n",
        "# Function to rename the model files after training\n",
        "def rename_model_file(model_name):\n",
        "    # Find the latest file saved in the checkpoint directory\n",
        "    latest_file = max(\n",
        "        [f for f in os.listdir(checkpoint_dir) if model_name in f],\n",
        "        key=lambda x: os.path.getctime(os.path.join(checkpoint_dir, x))\n",
        "    )\n",
        "\n",
        "    # Define the new name for the model\n",
        "    new_model_file = os.path.join(checkpoint_dir, f'{model_name}.pth')\n",
        "\n",
        "    # Rename the file\n",
        "    shutil.move(os.path.join(checkpoint_dir, latest_file), new_model_file)\n",
        "    print(f\"Model saved and renamed to {new_model_file}\")\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_save_model(model_name):\n",
        "    config_dict = get_config(model_name)\n",
        "    print(f\"Training and saving model: {model_name}...\")\n",
        "\n",
        "    # Train and save the model using RecBole\n",
        "    result = run_recbole(config_dict=config_dict)\n",
        "\n",
        "    # Rename the saved model to avoid long names\n",
        "    rename_model_file(model_name)\n",
        "\n",
        "# Train and save models with simplified filenames\n",
        "train_and_save_model('BPR')\n",
        "train_and_save_model('ItemKNN')\n",
        "train_and_save_model('Pop')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KcG7UPGSrx3",
        "outputId": "3f9336cc-973f-4a92-f6fe-50028a9a5f42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-caebcb1d-6f2a-4cc6-ad58-d5aaf6dcb58a.json] will not be used in RecBole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and saving model: BPR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|██████████████████████████████████████████████████| 40/40 [00:01<00:00, 23.67it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:01<00:00, 376.05it/s]\n",
            "Train     1: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 52.72it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 653.10it/s]\n",
            "Train     2: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 43.77it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 690.62it/s]\n",
            "Train     3: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 43.27it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 509.48it/s]\n",
            "Train     4: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 43.47it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 876.52it/s]\n",
            "Train     5: 100%|██████████████████████████████████████████████████| 40/40 [00:01<00:00, 35.59it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 606.26it/s]\n",
            "Train     6: 100%|██████████████████████████████████████████████████| 40/40 [00:01<00:00, 36.48it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:01<00:00, 419.96it/s]\n",
            "Train     7: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 65.56it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 889.75it/s]\n",
            "Train     8: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 65.33it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 886.13it/s]\n",
            "Train     9: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 107.27it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1317.47it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1543.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/BPR.pth\n",
            "Training and saving model: ItemKNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-caebcb1d-6f2a-4cc6-ad58-d5aaf6dcb58a.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|█████████████████████████████████████████████████| 79/79 [00:00<00:00, 295.66it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 629.50it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 657.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/ItemKNN.pth\n",
            "Training and saving model: Pop...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-caebcb1d-6f2a-4cc6-ad58-d5aaf6dcb58a.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|█████████████████████████████████████████████████| 79/79 [00:00<00:00, 245.35it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1140.77it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1234.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/Pop.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recbole.quick_start import load_data_and_model\n",
        "\n",
        "# Function to load the saved model and return model, dataset, and dataloader\n",
        "def load_saved_model(model_name):\n",
        "    \"\"\"\n",
        "    Load a saved model along with the dataset and dataloader.\n",
        "\n",
        "    :param model_name: The name of the model to load (BPR, ItemKNN, Pop)\n",
        "    :return: config, model, dataset, dataloader_train, dataloader_test\n",
        "    \"\"\"\n",
        "    model_file = f'./saved_models/{model_name}.pth'  # Path to the saved model\n",
        "\n",
        "    print(f\"Loading saved model: {model_name} from {model_file}...\")\n",
        "\n",
        "    # Load the model, config, dataset, and dataloaders\n",
        "    result = load_data_and_model(model_file)\n",
        "\n",
        "    # Unpack and return the necessary components\n",
        "    config, model, dataset, dataloader_train, dataloader_test, _ = result\n",
        "    print(f\"Model {model_name} loaded successfully.\")\n",
        "\n",
        "    return config, model, dataset, dataloader_train, dataloader_test\n",
        "\n",
        "# Load all three models: BPR, ItemKNN, Pop\n",
        "bpr_config, bpr_model, bpr_dataset, bpr_dataloader_train, bpr_dataloader_test = load_saved_model('BPR')\n",
        "itemknn_config, itemknn_model, itemknn_dataset, itemknn_dataloader_train, itemknn_dataloader_test = load_saved_model('ItemKNN')\n",
        "pop_config, pop_model, pop_dataset, pop_dataloader_train, pop_dataloader_test = load_saved_model('Pop')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8R_3o5rVwFY",
        "outputId": "e3a0b3be-94f1-49f0-fdd0-69d4218d7913"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved model: BPR from ./saved_models/BPR.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BPR loaded successfully.\n",
            "Loading saved model: ItemKNN from ./saved_models/ItemKNN.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ItemKNN loaded successfully.\n",
            "Loading saved model: Pop from ./saved_models/Pop.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Pop loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to generate top-k recommendations for a given model and dataloader\n",
        "def get_topk_recommendations(model, dataloader, topk=10):\n",
        "    \"\"\"\n",
        "    Generate top-k recommendations for a given model and dataloader.\n",
        "\n",
        "    :param model: The trained model (e.g., BPR, ItemKNN, Pop)\n",
        "    :param dataloader: The dataloader for the test set\n",
        "    :param topk: The number of top recommendations to generate (default: 10)\n",
        "    :return: List of top-k recommended items for each user\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    topk_recommendations = []  # Placeholder to store top-k recommendations\n",
        "\n",
        "    # Generate recommendations using the model and dataloader\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]  # Get the interaction tensor (user, item interactions)\n",
        "        scores = model.full_sort_predict(interaction)  # Predict scores for all items\n",
        "        topk_items = torch.topk(scores, k=topk, dim=-1).indices  # Get top-k items\n",
        "        topk_recommendations.append(topk_items.cpu().numpy())  # Append to the list\n",
        "\n",
        "    return topk_recommendations\n",
        "\n",
        "# Generate top-k recommendations for each model and store them in memory\n",
        "print(\"Generating Top-K (10) Recommendations for each model...\")\n",
        "\n",
        "# BPR Model Recommendations\n",
        "bpr_topk_recs = get_topk_recommendations(bpr_model, bpr_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for BPR Model:\\n{bpr_topk_recs[:5]}\")  # Print first 5 recommendations for inspection\n",
        "\n",
        "# ItemKNN Model Recommendations\n",
        "itemknn_topk_recs = get_topk_recommendations(itemknn_model, itemknn_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for ItemKNN Model:\\n{itemknn_topk_recs[:5]}\")  # Print first 5 recommendations for inspection\n",
        "\n",
        "# Pop Model Recommendations\n",
        "pop_topk_recs = get_topk_recommendations(pop_model, pop_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for Pop Model:\\n{pop_topk_recs[:5]}\")  # Print first 5 recommendations for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFmyOLsKWW3t",
        "outputId": "04f297e7-ddcc-4d7a-e386-8fedf3406452"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Top-K (10) Recommendations for each model...\n",
            "Top-10 Recommendations for BPR Model:\n",
            "[array([1736,  358,   53, 2041,   50, 1733, 2087, 1744,  290,  102]), array([1736, 2041, 1733, 2087, 1900, 1785, 1715, 1841, 1845, 1931]), array([1736, 2041, 1733, 1900, 1785, 2087, 1715, 1845, 1931, 1841]), array([1736, 2041,   53, 1733,  358,   50, 1785, 1900, 1715, 1840]), array([1736, 2041, 1733,  358, 1785,   53, 1900,   50, 1715,  102])]\n",
            "Top-10 Recommendations for ItemKNN Model:\n",
            "[array([1824, 1707, 2087, 1820, 2048, 1962, 2160, 1709, 1786, 1781]), array([1931, 1845, 1796, 1715, 1875, 1785, 1900, 1741, 1863, 2005]), array([1784, 1741, 1785, 1924, 1938, 1802, 2041, 1875, 1783, 2155]), array([1785, 1796, 1900, 1931, 1845, 2041, 1736, 1923, 1786, 1875]), array([ 102,  217,  113,  103, 1785,  248,  348,  322,  162,   54])]\n",
            "Top-10 Recommendations for Pop Model:\n",
            "[array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def greedy_rerank(model, dataloader, dataset, topk=10, diversity_weight=0.5):\n",
        "    \"\"\"\n",
        "    Greedy re-ranking to balance relevance (model's score) and diversity\n",
        "    among the recommended items.\n",
        "\n",
        "    :param model: The recommendation model (BPR, ItemKNN, or Pop)\n",
        "    :param dataloader: The test dataloader for generating recommendations\n",
        "    :param dataset: The dataset object to access item_num\n",
        "    :param topk: Number of items to recommend after re-ranking (default: 10)\n",
        "    :param diversity_weight: Weight controlling the trade-off between relevance and diversity (0 = no diversity, 1 = max diversity)\n",
        "    :return: Re-ranked top-k recommendations\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    re_ranked_recommendations = []  # Placeholder for re-ranked recommendations\n",
        "    num_items = dataset.item_num  # Number of items in the dataset\n",
        "\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]  # Get interaction tensor\n",
        "        scores = model.full_sort_predict(interaction).squeeze()  # Predict scores for all items and flatten\n",
        "        initial_topk_items = torch.topk(scores, k=topk*2, dim=-1).indices  # Get initial 2x top-k items\n",
        "\n",
        "        selected_items = []  # Placeholder for selected items after re-ranking\n",
        "\n",
        "        # Add the first item (highest relevance score)\n",
        "        selected_items.append(initial_topk_items[0].item())\n",
        "\n",
        "        # Greedily add items to maximize diversity\n",
        "        for _ in range(1, topk):\n",
        "            best_item = None\n",
        "            best_score = -float('inf')\n",
        "\n",
        "            # Loop over the remaining items and select the best one based on a trade-off between score and diversity\n",
        "            for item in initial_topk_items:\n",
        "                if item.item() in selected_items:\n",
        "                    continue  # Skip already selected items\n",
        "\n",
        "                if item.item() >= num_items:  # Ensure item index is valid\n",
        "                    continue  # Skip items that are out of bounds\n",
        "\n",
        "                # Different logic for models without embeddings\n",
        "                if hasattr(model, 'item_embedding'):  # BPR model with embeddings\n",
        "                    # Calculate diversity: Use cosine similarity\n",
        "                    diversity = 0\n",
        "                    for selected_item in selected_items:\n",
        "                        if selected_item >= num_items:  # Ensure selected_item index is valid\n",
        "                            continue\n",
        "\n",
        "                        sim = F.cosine_similarity(model.item_embedding.weight[item].unsqueeze(0),\n",
        "                                                  model.item_embedding.weight[selected_item].unsqueeze(0)).item()\n",
        "                        diversity += 1 - sim  # Higher difference = more diversity\n",
        "\n",
        "                    diversity = diversity / len(selected_items)  # Average diversity for the current item\n",
        "                else:\n",
        "                    # For models like ItemKNN or Pop, we'll just consider the relevance scores\n",
        "                    diversity = 0\n",
        "\n",
        "                # Relevance score for the current item\n",
        "                score = scores[item].item()\n",
        "\n",
        "                # Combine relevance and diversity into a final score\n",
        "                combined_score = (1 - diversity_weight) * score + diversity_weight * diversity\n",
        "\n",
        "                # Select the item with the best combined score\n",
        "                if combined_score > best_score:\n",
        "                    best_score = combined_score\n",
        "                    best_item = item.item()\n",
        "\n",
        "            # Add the best item to the selected items\n",
        "            if best_item is not None:\n",
        "                selected_items.append(best_item)\n",
        "\n",
        "        re_ranked_recommendations.append(selected_items)\n",
        "\n",
        "    return re_ranked_recommendations\n",
        "\n",
        "\n",
        "# Apply greedy re-ranking for each model's recommendations\n",
        "print(\"Applying Greedy Re-ranking for each model...\")\n",
        "\n",
        "# BPR Re-ranked Recommendations (uses item embeddings)\n",
        "bpr_re_ranked_recs = greedy_rerank(bpr_model, bpr_dataloader_test, bpr_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for BPR Model:\\n{bpr_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations\n",
        "\n",
        "# ItemKNN Re-ranked Recommendations (without item embeddings)\n",
        "itemknn_re_ranked_recs = greedy_rerank(itemknn_model, itemknn_dataloader_test, itemknn_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for ItemKNN Model:\\n{itemknn_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations\n",
        "\n",
        "# Pop Re-ranked Recommendations (without item embeddings)\n",
        "pop_re_ranked_recs = greedy_rerank(pop_model, pop_dataloader_test, pop_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for Pop Model:\\n{pop_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMFJQTW9Ks8R",
        "outputId": "329e1f52-c034-4371-bd15-4248d07d1398"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying Greedy Re-ranking for each model...\n",
            "Re-ranked Top-10 Recommendations for BPR Model:\n",
            "[[1736, 358, 53, 50, 290, 102, 158, 61, 190], [1736], [1736], [1736, 53, 358, 50, 158, 102, 61, 404, 217], [1736, 358, 53, 50, 102, 217, 32, 162]]\n",
            "Re-ranked Top-10 Recommendations for ItemKNN Model:\n",
            "[[1824], [1931], [1784], [1785], [102, 217, 113, 103, 248, 348, 322, 162, 54, 192]]\n",
            "Re-ranked Top-10 Recommendations for Pop Model:\n",
            "[[1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Reuse the NDCG calculation function you provided\n",
        "def calculate_ndcg_at_k(topk_recs, ground_truth, k=10):\n",
        "    def dcg_at_k(recommended_items, relevant_items, k):\n",
        "        dcg = 0.0\n",
        "        for i in range(min(k, len(recommended_items))):\n",
        "            if recommended_items[i] in relevant_items:\n",
        "                dcg += 1 / np.log2(i + 2)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(relevant_items, k):\n",
        "        idcg = 0.0\n",
        "        for i in range(min(k, len(relevant_items))):\n",
        "            idcg += 1 / np.log2(i + 2)\n",
        "        return idcg\n",
        "\n",
        "    total_ndcg = 0.0\n",
        "    num_users = len(topk_recs)\n",
        "\n",
        "    for user_idx in range(num_users):\n",
        "        recommended_items = topk_recs[user_idx]\n",
        "        relevant_items = ground_truth[user_idx]\n",
        "\n",
        "        # Ensure both are lists or tensors\n",
        "        if isinstance(recommended_items, torch.Tensor):\n",
        "            recommended_items = recommended_items.tolist()\n",
        "        if isinstance(relevant_items, torch.Tensor):\n",
        "            relevant_items = relevant_items.tolist()\n",
        "        if isinstance(recommended_items, int):\n",
        "            recommended_items = [recommended_items]\n",
        "        if isinstance(relevant_items, int):\n",
        "            relevant_items = [relevant_items]\n",
        "\n",
        "        # Calculate DCG@K for this user\n",
        "        dcg = dcg_at_k(recommended_items, relevant_items, k)\n",
        "        # Calculate IDCG@K for this user\n",
        "        idcg = idcg_at_k(relevant_items, k)\n",
        "\n",
        "        if idcg == 0:\n",
        "            ndcg = 0.0\n",
        "        else:\n",
        "            ndcg = dcg / idcg\n",
        "\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / num_users\n",
        "\n",
        "# Extract ground truth function\n",
        "def extract_ground_truth_from_dataset(dataset, test=True):\n",
        "    ground_truth = []\n",
        "    data = dataset.inter_feat if test else dataset.train_data\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        item_id = data['item_id'][i]\n",
        "        ground_truth.append(item_id)\n",
        "\n",
        "    return ground_truth\n",
        "\n",
        "# Extract the ground truth interactions from the test dataset for each model\n",
        "bpr_ground_truth = extract_ground_truth_from_dataset(bpr_dataset, test=True)\n",
        "itemknn_ground_truth = extract_ground_truth_from_dataset(itemknn_dataset, test=True)\n",
        "pop_ground_truth = extract_ground_truth_from_dataset(pop_dataset, test=True)\n",
        "\n",
        "# Calculate NDCG for non-re-ranked recommendations\n",
        "print(\"Evaluating non-re-ranked recommendations:\")\n",
        "ndcg_bpr = calculate_ndcg_at_k(bpr_topk_recs, bpr_ground_truth, k=10)\n",
        "ndcg_itemknn = calculate_ndcg_at_k(itemknn_topk_recs, itemknn_ground_truth, k=10)\n",
        "ndcg_pop = calculate_ndcg_at_k(pop_topk_recs, pop_ground_truth, k=10)\n",
        "\n",
        "print(f\"NDCG@10 for BPR: {ndcg_bpr}\")\n",
        "print(f\"NDCG@10 for ItemKNN: {ndcg_itemknn}\")\n",
        "print(f\"NDCG@10 for Pop: {ndcg_pop}\")\n",
        "\n",
        "# Calculate NDCG for re-ranked recommendations\n",
        "print(\"\\nEvaluating re-ranked recommendations:\")\n",
        "ndcg_bpr_reranked = calculate_ndcg_at_k(bpr_re_ranked_recs, bpr_ground_truth, k=10)\n",
        "ndcg_itemknn_reranked = calculate_ndcg_at_k(itemknn_re_ranked_recs, itemknn_ground_truth, k=10)\n",
        "ndcg_pop_reranked = calculate_ndcg_at_k(pop_re_ranked_recs, pop_ground_truth, k=10)\n",
        "\n",
        "print(f\"NDCG@10 for Re-ranked BPR: {ndcg_bpr_reranked}\")\n",
        "print(f\"NDCG@10 for Re-ranked ItemKNN: {ndcg_itemknn_reranked}\")\n",
        "print(f\"NDCG@10 for Re-ranked Pop: {ndcg_pop_reranked}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa4mT6MjPkRo",
        "outputId": "5acec2b1-0d25-44c4-d028-98c63c046401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating non-re-ranked recommendations:\n",
            "NDCG@10 for BPR: 0.01211335827200395\n",
            "NDCG@10 for ItemKNN: 0.004912738467097417\n",
            "NDCG@10 for Pop: 0.028602174116840032\n",
            "\n",
            "Evaluating re-ranked recommendations:\n",
            "NDCG@10 for Re-ranked BPR: 0.014763416544407262\n",
            "NDCG@10 for Re-ranked ItemKNN: 0.005555746321842406\n",
            "NDCG@10 for Re-ranked Pop: 0.021414940828463416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_average_popularity(topk_recs, item_popularity):\n",
        "    total_popularity = 0\n",
        "    num_users = len(topk_recs)\n",
        "\n",
        "    for recs in topk_recs:\n",
        "        # Sum the popularity of recommended items, skip if index is out of range\n",
        "        total_popularity += sum(item_popularity[item] for item in recs if item < len(item_popularity))\n",
        "\n",
        "    return total_popularity / (num_users * len(topk_recs[0]))\n",
        "\n",
        "\n",
        "def calculate_gini_index(topk_recs, item_popularity):\n",
        "    all_recs = [item for recs in topk_recs for item in recs if item < len(item_popularity)]\n",
        "    item_freq = np.array([all_recs.count(i) for i in range(len(item_popularity))])\n",
        "    item_freq = np.sort(item_freq)\n",
        "    n = len(item_freq)\n",
        "    index = np.arange(1, n + 1)\n",
        "    gini = (2 * np.sum(index * item_freq) / np.sum(item_freq)) - (n + 1) / n\n",
        "    return gini\n",
        "\n",
        "\n",
        "# Function to calculate ItemCoverage\n",
        "def calculate_item_coverage(topk_recs, total_items):\n",
        "    unique_items = set(item for recs in topk_recs for item in recs)\n",
        "    coverage = len(unique_items) / total_items\n",
        "    return coverage\n",
        "\n",
        "# Function to calculate ShannonEntropy\n",
        "def calculate_shannon_entropy(topk_recs):\n",
        "    all_recs = [item for recs in topk_recs for item in recs]\n",
        "    item_freq = np.array([all_recs.count(i) for i in set(all_recs)])\n",
        "    prob = item_freq / item_freq.sum()\n",
        "    entropy = -np.sum(prob * np.log2(prob))\n",
        "    return entropy\n",
        "\n",
        "def calculate_tail_percentage(topk_recs, item_popularity, tail_threshold=0.2):\n",
        "    num_items = len(item_popularity)\n",
        "    threshold = int(tail_threshold * num_items)  # Items in the tail are the least popular ones\n",
        "    tail_items = set(np.argsort(item_popularity)[:threshold])\n",
        "\n",
        "    num_tail_items = sum(item in tail_items for recs in topk_recs for item in recs if item < len(item_popularity))\n",
        "    total_recommendations = len(topk_recs) * len(topk_recs[0])\n",
        "\n",
        "    return num_tail_items / total_recommendations\n"
      ],
      "metadata": {
        "id": "GgUmIv8ekWo7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate item popularity from the dataset\n",
        "def calculate_item_popularity(dataset):\n",
        "    item_popularity = {}\n",
        "\n",
        "    # Iterate through all interactions in the dataset\n",
        "    for item_id in dataset['item_id']:\n",
        "        if item_id in item_popularity:\n",
        "            item_popularity[item_id] += 1\n",
        "        else:\n",
        "            item_popularity[item_id] = 1\n",
        "\n",
        "    # Convert to a list where index is item_id and value is the popularity\n",
        "    total_items = dataset.item_num  # Ensure this covers all items in the dataset\n",
        "    item_popularity_list = [item_popularity.get(i, 0) for i in range(total_items)]\n",
        "\n",
        "    return item_popularity_list\n",
        "\n",
        "\n",
        "# Example usage after loading the dataset\n",
        "item_popularity = calculate_item_popularity(bpr_dataset)  # Calculate item popularity for the BPR dataset"
      ],
      "metadata": {
        "id": "NdxUOi2wkYCR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the new metrics for non-re-ranked recommendations\n",
        "average_popularity_bpr = calculate_average_popularity(bpr_topk_recs, item_popularity)\n",
        "gini_index_bpr = calculate_gini_index(bpr_topk_recs, item_popularity)\n",
        "item_coverage_bpr = calculate_item_coverage(bpr_topk_recs, bpr_dataset.item_num)\n",
        "shannon_entropy_bpr = calculate_shannon_entropy(bpr_topk_recs)\n",
        "tail_percentage_bpr = calculate_tail_percentage(bpr_topk_recs, item_popularity)\n",
        "\n",
        "# Print the results for BPR model\n",
        "print(f\"AveragePopularity for BPR: {average_popularity_bpr}\")\n",
        "print(f\"GiniIndex for BPR: {gini_index_bpr}\")\n",
        "print(f\"ItemCoverage for BPR: {item_coverage_bpr}\")\n",
        "print(f\"ShannonEntropy for BPR: {shannon_entropy_bpr}\")\n",
        "print(f\"TailPercentage for BPR: {tail_percentage_bpr}\")\n",
        "\n",
        "# Calculate metrics for re-ranked recommendations\n",
        "average_popularity_bpr_reranked = calculate_average_popularity(bpr_re_ranked_recs, item_popularity)\n",
        "gini_index_bpr_reranked = calculate_gini_index(bpr_re_ranked_recs, item_popularity)\n",
        "item_coverage_bpr_reranked = calculate_item_coverage(bpr_re_ranked_recs, bpr_dataset.item_num)\n",
        "shannon_entropy_bpr_reranked = calculate_shannon_entropy(bpr_re_ranked_recs)\n",
        "tail_percentage_bpr_reranked = calculate_tail_percentage(bpr_re_ranked_recs, item_popularity)\n",
        "\n",
        "# Print results for re-ranked BPR model\n",
        "print(f\"AveragePopularity for Re-ranked BPR: {average_popularity_bpr_reranked}\")\n",
        "print(f\"GiniIndex for Re-ranked BPR: {gini_index_bpr_reranked}\")\n",
        "print(f\"ItemCoverage for Re-ranked BPR: {item_coverage_bpr_reranked}\")\n",
        "print(f\"ShannonEntropy for Re-ranked BPR: {shannon_entropy_bpr_reranked}\")\n",
        "print(f\"TailPercentage for Re-ranked BPR: {tail_percentage_bpr_reranked}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXu2ooY2kcdJ",
        "outputId": "bc5d3721-4346-4637-a1fc-4e4555d624dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AveragePopularity for BPR: 0.0\n",
            "GiniIndex for BPR: 3354.390600791489\n",
            "ItemCoverage for BPR: 0.0285204991087344\n",
            "ShannonEntropy for BPR: 4.88347990175488\n",
            "TailPercentage for BPR: 0.0\n",
            "AveragePopularity for Re-ranked BPR: 0.0\n",
            "GiniIndex for Re-ranked BPR: 3353.7849043123615\n",
            "ItemCoverage for Re-ranked BPR: 0.019013666072489603\n",
            "ShannonEntropy for Re-ranked BPR: 4.129052069247205\n",
            "TailPercentage for Re-ranked BPR: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relevance_rerank(model, dataloader, dataset, topk=10):\n",
        "    \"\"\"\n",
        "    Relevance re-ranking based purely on the model's predicted scores.\n",
        "\n",
        "    :param model: The recommendation model (BPR, ItemKNN, or Pop)\n",
        "    :param dataloader: The test dataloader for generating recommendations\n",
        "    :param dataset: The dataset object to access item_num\n",
        "    :param topk: Number of items to recommend after re-ranking (default: 10)\n",
        "    :return: Re-ranked top-k recommendations\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    re_ranked_recommendations = []  # Placeholder for re-ranked recommendations\n",
        "\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]  # Get interaction tensor\n",
        "        scores = model.full_sort_predict(interaction).squeeze()  # Predict scores for all items and flatten\n",
        "        topk_items = torch.topk(scores, k=topk, dim=-1).indices  # Get the top-k items based purely on relevance\n",
        "\n",
        "        re_ranked_recommendations.append(topk_items.cpu().numpy())  # Append to the re-ranked list\n",
        "\n",
        "    return re_ranked_recommendations"
      ],
      "metadata": {
        "id": "4WAU8WSoxhXO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply relevance-based re-ranking for each model\n",
        "print(\"Applying Relevance-Based Re-ranking for each model...\")\n",
        "\n",
        "# BPR Relevance-Based Re-ranked Recommendations\n",
        "bpr_relevance_re_ranked_recs = relevance_rerank(bpr_model, bpr_dataloader_test, bpr_dataset, topk=10)\n",
        "print(f\"Relevance-Based Re-ranked Top-10 Recommendations for BPR Model:\\n{bpr_relevance_re_ranked_recs[:5]}\")\n",
        "\n",
        "# ItemKNN Relevance-Based Re-ranked Recommendations\n",
        "itemknn_relevance_re_ranked_recs = relevance_rerank(itemknn_model, itemknn_dataloader_test, itemknn_dataset, topk=10)\n",
        "print(f\"Relevance-Based Re-ranked Top-10 Recommendations for ItemKNN Model:\\n{itemknn_relevance_re_ranked_recs[:5]}\")\n",
        "\n",
        "# Pop Relevance-Based Re-ranked Recommendations\n",
        "pop_relevance_re_ranked_recs = relevance_rerank(pop_model, pop_dataloader_test, pop_dataset, topk=10)\n",
        "print(f\"Relevance-Based Re-ranked Top-10 Recommendations for Pop Model:\\n{pop_relevance_re_ranked_recs[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7tacOS6xlmC",
        "outputId": "62411ca3-cb73-42d4-cc6d-95958a215960"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying Relevance-Based Re-ranking for each model...\n",
            "Relevance-Based Re-ranked Top-10 Recommendations for BPR Model:\n",
            "[array([1736,  358,   53, 2041,   50, 1733, 2087, 1744,  290,  102]), array([1736, 2041, 1733, 2087, 1900, 1785, 1715, 1841, 1845, 1931]), array([1736, 2041, 1733, 1900, 1785, 2087, 1715, 1845, 1931, 1841]), array([1736, 2041,   53, 1733,  358,   50, 1785, 1900, 1715, 1840]), array([1736, 2041, 1733,  358, 1785,   53, 1900,   50, 1715,  102])]\n",
            "Relevance-Based Re-ranked Top-10 Recommendations for ItemKNN Model:\n",
            "[array([1824, 1707, 2087, 1820, 2048, 1962, 2160, 1709, 1786, 1781]), array([1931, 1845, 1796, 1715, 1875, 1785, 1900, 1741, 1863, 2005]), array([1784, 1741, 1785, 1924, 1938, 1802, 2041, 1875, 1783, 2155]), array([1785, 1796, 1900, 1931, 1845, 2041, 1736, 1923, 1786, 1875]), array([ 102,  217,  113,  103, 1785,  248,  348,  322,  162,   54])]\n",
            "Relevance-Based Re-ranked Top-10 Recommendations for Pop Model:\n",
            "[array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate relevance-based re-ranked recommendations using the same metrics\n",
        "\n",
        "# NDCG evaluation\n",
        "print(\"\\nEvaluating Relevance-Based Re-ranked recommendations:\")\n",
        "ndcg_bpr_relevance_reranked = calculate_ndcg_at_k(bpr_relevance_re_ranked_recs, bpr_ground_truth, k=10)\n",
        "ndcg_itemknn_relevance_reranked = calculate_ndcg_at_k(itemknn_relevance_re_ranked_recs, itemknn_ground_truth, k=10)\n",
        "ndcg_pop_relevance_reranked = calculate_ndcg_at_k(pop_relevance_re_ranked_recs, pop_ground_truth, k=10)\n",
        "\n",
        "print(f\"NDCG@10 for Relevance-Based Re-ranked BPR: {ndcg_bpr_relevance_reranked}\")\n",
        "print(f\"NDCG@10 for Relevance-Based Re-ranked ItemKNN: {ndcg_itemknn_relevance_reranked}\")\n",
        "print(f\"NDCG@10 for Relevance-Based Re-ranked Pop: {ndcg_pop_relevance_reranked}\")\n",
        "\n",
        "# Calculate the other metrics (e.g., Average Popularity, Gini Index, etc.)\n",
        "average_popularity_bpr_relevance_reranked = calculate_average_popularity(bpr_relevance_re_ranked_recs, item_popularity)\n",
        "gini_index_bpr_relevance_reranked = calculate_gini_index(bpr_relevance_re_ranked_recs, item_popularity)\n",
        "item_coverage_bpr_relevance_reranked = calculate_item_coverage(bpr_relevance_re_ranked_recs, bpr_dataset.item_num)\n",
        "shannon_entropy_bpr_relevance_reranked = calculate_shannon_entropy(bpr_relevance_re_ranked_recs)\n",
        "tail_percentage_bpr_relevance_reranked = calculate_tail_percentage(bpr_relevance_re_ranked_recs, item_popularity)\n",
        "\n",
        "# Print results for relevance-based re-ranked BPR model\n",
        "print(f\"AveragePopularity for Relevance-Based Re-ranked BPR: {average_popularity_bpr_relevance_reranked}\")\n",
        "print(f\"GiniIndex for Relevance-Based Re-ranked BPR: {gini_index_bpr_relevance_reranked}\")\n",
        "print(f\"ItemCoverage for Relevance-Based Re-ranked BPR: {item_coverage_bpr_relevance_reranked}\")\n",
        "print(f\"ShannonEntropy for Relevance-Based Re-ranked BPR: {shannon_entropy_bpr_relevance_reranked}\")\n",
        "print(f\"TailPercentage for Relevance-Based Re-ranked BPR: {tail_percentage_bpr_relevance_reranked}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwWxWQ7Vxq01",
        "outputId": "72d3a15c-6d3f-442a-f622-c511cb032495"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Relevance-Based Re-ranked recommendations:\n",
            "NDCG@10 for Relevance-Based Re-ranked BPR: 0.01211335827200395\n",
            "NDCG@10 for Relevance-Based Re-ranked ItemKNN: 0.004912738467097417\n",
            "NDCG@10 for Relevance-Based Re-ranked Pop: 0.028602174116840032\n",
            "AveragePopularity for Relevance-Based Re-ranked BPR: 0.0\n",
            "GiniIndex for Relevance-Based Re-ranked BPR: 3354.390600791489\n",
            "ItemCoverage for Relevance-Based Re-ranked BPR: 0.0285204991087344\n",
            "ShannonEntropy for Relevance-Based Re-ranked BPR: 4.88347990175488\n",
            "TailPercentage for Relevance-Based Re-ranked BPR: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relevance-Based Re-ranking Results Overview\n",
        "\n",
        "Let’s break down the results you’ve obtained for the **Relevance-Based Re-ranking** method and compare them with the previous **Greedy Re-ranking** and **original** recommendations:\n",
        "\n",
        "### NDCG@10 Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 0.0121\n",
        "- **Greedy Re-ranked BPR:** 0.0148\n",
        "- **Original BPR:** 0.0121\n",
        "\n",
        "**Observation:** The NDCG for the relevance-based re-ranking is identical to the original BPR recommendations, which is expected since this method prioritizes relevance without considering diversity. However, the greedy re-ranking slightly improved NDCG by incorporating diversity in addition to relevance.\n",
        "\n",
        "### Average Popularity Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 0.0\n",
        "- **Greedy Re-ranked BPR:** 0.0\n",
        "- **Original BPR:** 0.0\n",
        "\n",
        "**Observation:** The average popularity for all BPR models is 0, which likely indicates that the items recommended are very unpopular or niche, possibly due to a low number of interactions. This result remains the same across all methods.\n",
        "\n",
        "### Gini Index Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 3354.39\n",
        "- **Greedy Re-ranked BPR:** 3353.78\n",
        "- **Original BPR:** 3354.39\n",
        "\n",
        "**Observation:** The Gini Index, which measures inequality in recommendations, remains almost identical between relevance-based and original BPR, as expected. The greedy re-ranking slightly lowered it, which is good as it suggests more diversity.\n",
        "\n",
        "### Item Coverage Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 0.0285\n",
        "- **Greedy Re-ranked BPR:** 0.0190\n",
        "- **Original BPR:** 0.0285\n",
        "\n",
        "**Observation:** The relevance-based re-ranking provides the same item coverage as the original recommendations, while the greedy re-ranking reduced item coverage, indicating that greedy re-ranking may be focusing on a narrower set of items to optimize for diversity.\n",
        "\n",
        "### Shannon Entropy Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 4.88\n",
        "- **Greedy Re-ranked BPR:** 4.12\n",
        "- **Original BPR:** 4.88\n",
        "\n",
        "**Observation:** Relevance-based re-ranking has higher Shannon Entropy (similar to the original BPR), which suggests a more even distribution of recommended items. The greedy re-ranking reduced entropy, likely due to the focus on balancing diversity with relevance.\n",
        "\n",
        "### Tail Percentage Comparison:\n",
        "- **Relevance-Based Re-ranked BPR:** 0.0\n",
        "- **Greedy Re-ranked BPR:** 0.0\n",
        "- **Original BPR:** 0.0\n",
        "\n",
        "**Observation:** Both the original and re-ranked recommendations (relevance-based and greedy) do not include any items from the tail, indicating that none of the recommended items are from the least popular portion of the catalog.\n",
        "\n",
        "### Conclusion:\n",
        "- **Relevance-Based Re-ranking** gives results that are almost identical to the **original** BPR recommendations because it doesn't add any additional constraints like diversity. It performs similarly on NDCG and other metrics like coverage and entropy.\n",
        "- **Greedy Re-ranking**, however, introduces slight improvements in NDCG at the cost of reduced item coverage and entropy. This method likely performs better when diversity is valued alongside relevance."
      ],
      "metadata": {
        "id": "hOJfg25ByuOj"
      }
    }
  ]
}