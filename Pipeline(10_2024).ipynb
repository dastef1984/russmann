{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYf58hnUQLKoR16A3S4dS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dastef1984/russmann/blob/master/Pipeline(10_2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTx7jOyUR3qQ",
        "outputId": "2a355b72-e724-444c-e475-ba5d97eb245b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recbole\n",
            "  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (4.66.5)\n",
            "Collecting colorlog==4.7.2 (from recbole)\n",
            "  Downloading colorlog-4.7.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting colorama==0.4.4 (from recbole)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from recbole) (1.5.2)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (6.0.2)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (2.17.0)\n",
            "Collecting thop>=0.1.1.post2207130030 (from recbole)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from recbole) (0.9.0)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from recbole) (5.24.1)\n",
            "Collecting texttable>=0.9.0 (from recbole)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->recbole) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->recbole) (24.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->recbole) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->recbole) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->recbole) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->recbole) (1.3.0)\n",
            "Downloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: texttable, colorlog, colorama, thop, recbole\n",
            "Successfully installed colorama-0.4.4 colorlog-4.7.2 recbole-1.2.0 texttable-1.7.0 thop-0.1.1.post2209072238\n",
            "Collecting ray\n",
            "  Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Downloading ray-2.37.0-cp310-cp310-manylinux2014_x86_64.whl (65.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.37.0\n",
            "Collecting kmeans-pytorch\n",
            "  Downloading kmeans_pytorch-0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading kmeans_pytorch-0.3-py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install recbole\n",
        "!pip install ray\n",
        "!pip install kmeans-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from recbole.quick_start import run_recbole\n",
        "\n",
        "# Path where models will be saved\n",
        "checkpoint_dir = './saved_models/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Dataset and Model Configuration\n",
        "dataset_name = 'ml-100k'\n",
        "data_path = 'dataset/'\n",
        "\n",
        "# Define metrics for evaluation (only NDCG for now)\n",
        "metrics = ['MRR']\n",
        "\n",
        "# Check if the dataset path exists\n",
        "if not os.path.exists(data_path):\n",
        "    print(f\"Dataset path {data_path} does not exist. Please ensure the dataset is available.\")\n",
        "else:\n",
        "    print(f\"Dataset {dataset_name} is ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZjoFukR9nf",
        "outputId": "b9f0bdc9-bdcd-4bec-cfd4-5bbfc1270dab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path dataset/ does not exist. Please ensure the dataset is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Function to get configuration dictionary for each model\n",
        "def get_config(model_name):\n",
        "    config_dict = {\n",
        "        'model': model_name,\n",
        "        'dataset': dataset_name,\n",
        "        'data_path': data_path,\n",
        "        'epochs': 10,    # Modify if you want to adjust training duration\n",
        "        'topk': 10,      # We'll evaluate Top-K items (for MRR)\n",
        "        'metrics': metrics,\n",
        "        'checkpoint_dir': checkpoint_dir,  # Define checkpoint directory\n",
        "        'save_model': True,  # Ensure the model is saved\n",
        "    }\n",
        "    return config_dict\n",
        "\n",
        "# Function to rename the model files after training\n",
        "def rename_model_file(model_name):\n",
        "    # Find the latest file saved in the checkpoint directory\n",
        "    latest_file = max(\n",
        "        [f for f in os.listdir(checkpoint_dir) if model_name in f],\n",
        "        key=lambda x: os.path.getctime(os.path.join(checkpoint_dir, x))\n",
        "    )\n",
        "\n",
        "    # Define the new name for the model\n",
        "    new_model_file = os.path.join(checkpoint_dir, f'{model_name}.pth')\n",
        "\n",
        "    # Rename the file\n",
        "    shutil.move(os.path.join(checkpoint_dir, latest_file), new_model_file)\n",
        "    print(f\"Model saved and renamed to {new_model_file}\")\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_save_model(model_name):\n",
        "    config_dict = get_config(model_name)\n",
        "    print(f\"Training and saving model: {model_name}...\")\n",
        "\n",
        "    # Train and save the model using RecBole\n",
        "    result = run_recbole(config_dict=config_dict)\n",
        "\n",
        "    # Rename the saved model to avoid long names\n",
        "    rename_model_file(model_name)\n",
        "\n",
        "# Train and save models with simplified filenames\n",
        "train_and_save_model('BPR')\n",
        "train_and_save_model('ItemKNN')\n",
        "train_and_save_model('Pop')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KcG7UPGSrx3",
        "outputId": "94f1f2d5-7974-49a7-cf0b-85dde40ed2e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-e448ddf1-8a4b-4eec-b51b-aac2d3279bbb.json] will not be used in RecBole\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and saving model: BPR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 40.72it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:01<00:00, 424.87it/s]\n",
            "Train     1: 100%|██████████████████████████████████████████████████| 40/40 [00:02<00:00, 19.27it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:01<00:00, 271.27it/s]\n",
            "Train     2: 100%|██████████████████████████████████████████████████| 40/40 [00:01<00:00, 33.77it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:01<00:00, 426.49it/s]\n",
            "Train     3: 100%|██████████████████████████████████████████████████| 40/40 [00:01<00:00, 38.52it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1449.93it/s]\n",
            "Train     4: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 94.26it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1471.01it/s]\n",
            "Train     5: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 95.07it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1418.43it/s]\n",
            "Train     6: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 109.51it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1271.85it/s]\n",
            "Train     7: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 105.83it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1304.50it/s]\n",
            "Train     8: 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 100.06it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1466.76it/s]\n",
            "Train     9: 100%|██████████████████████████████████████████████████| 40/40 [00:00<00:00, 97.39it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1402.91it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1491.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/BPR.pth\n",
            "Training and saving model: ItemKNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-e448ddf1-8a4b-4eec-b51b-aac2d3279bbb.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|█████████████████████████████████████████████████| 79/79 [00:00<00:00, 292.91it/s]\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 657.26it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|███████████████████████████████████████████████| 472/472 [00:00<00:00, 671.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/ItemKNN.pth\n",
            "Training and saving model: Pop...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:command line args [-f /root/.local/share/jupyter/runtime/kernel-e448ddf1-8a4b-4eec-b51b-aac2d3279bbb.json] will not be used in RecBole\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
            "Train     0:   0%|                                                           | 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "Train     0: 100%|█████████████████████████████████████████████████| 79/79 [00:00<00:00, 273.93it/s]\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1746.52it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/trainer/trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
            "Evaluate   : 100%|██████████████████████████████████████████████| 472/472 [00:00<00:00, 1689.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved and renamed to ./saved_models/Pop.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recbole.quick_start import load_data_and_model\n",
        "\n",
        "# Function to load the saved model and return model, dataset, and dataloader\n",
        "def load_saved_model(model_name):\n",
        "    \"\"\"\n",
        "    Load a saved model along with the dataset and dataloader.\n",
        "\n",
        "    :param model_name: The name of the model to load (BPR, ItemKNN, Pop)\n",
        "    :return: config, model, dataset, dataloader_train, dataloader_test\n",
        "    \"\"\"\n",
        "    model_file = f'./saved_models/{model_name}.pth'  # Path to the saved model\n",
        "\n",
        "    print(f\"Loading saved model: {model_name} from {model_file}...\")\n",
        "\n",
        "    # Load the model, config, dataset, and dataloaders\n",
        "    result = load_data_and_model(model_file)\n",
        "\n",
        "    # Unpack and return the necessary components\n",
        "    config, model, dataset, dataloader_train, dataloader_test, _ = result\n",
        "    print(f\"Model {model_name} loaded successfully.\")\n",
        "\n",
        "    return config, model, dataset, dataloader_train, dataloader_test\n",
        "\n",
        "# Load all three models: BPR, ItemKNN, Pop\n",
        "bpr_config, bpr_model, bpr_dataset, bpr_dataloader_train, bpr_dataloader_test = load_saved_model('BPR')\n",
        "itemknn_config, itemknn_model, itemknn_dataset, itemknn_dataloader_train, itemknn_dataloader_test = load_saved_model('ItemKNN')\n",
        "pop_config, pop_model, pop_dataset, pop_dataloader_train, pop_dataloader_test = load_saved_model('Pop')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8R_3o5rVwFY",
        "outputId": "7c6d72b1-3666-4040-b0f9-2b1266d299f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading saved model: BPR from ./saved_models/BPR.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BPR loaded successfully.\n",
            "Loading saved model: ItemKNN from ./saved_models/ItemKNN.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ItemKNN loaded successfully.\n",
            "Loading saved model: Pop from ./saved_models/Pop.pth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/recbole/quick_start/quick_start.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_file)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Pop loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to generate top-k recommendations for a given model and dataloader\n",
        "def get_topk_recommendations(model, dataloader, topk=10):\n",
        "    \"\"\"\n",
        "    Generate top-k recommendations for a given model and dataloader.\n",
        "\n",
        "    :param model: The trained model (e.g., BPR, ItemKNN, Pop)\n",
        "    :param dataloader: The dataloader for the test set\n",
        "    :param topk: The number of top recommendations to generate (default: 10)\n",
        "    :return: List of top-k recommended items for each user\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    topk_recommendations = []  # Placeholder to store top-k recommendations\n",
        "\n",
        "    # Generate recommendations using the model and dataloader\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]  # Get the interaction tensor (user, item interactions)\n",
        "        scores = model.full_sort_predict(interaction)  # Predict scores for all items\n",
        "        topk_items = torch.topk(scores, k=topk, dim=-1).indices  # Get top-k items\n",
        "        topk_recommendations.append(topk_items.cpu().numpy())  # Append to the list\n",
        "\n",
        "    return topk_recommendations\n",
        "\n",
        "# Generate top-k recommendations for each model and store them in memory\n",
        "print(\"Generating Top-K (10) Recommendations for each model...\")\n",
        "\n",
        "# BPR Model Recommendations\n",
        "bpr_topk_recs = get_topk_recommendations(bpr_model, bpr_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for BPR Model:\\n{bpr_topk_recs[:5]}\")  # Print first 5 recommendations for inspection\n",
        "\n",
        "# ItemKNN Model Recommendations\n",
        "itemknn_topk_recs = get_topk_recommendations(itemknn_model, itemknn_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for ItemKNN Model:\\n{itemknn_topk_recs[:5]}\")  # Print first 5 recommendations for inspection\n",
        "\n",
        "# Pop Model Recommendations\n",
        "pop_topk_recs = get_topk_recommendations(pop_model, pop_dataloader_test, topk=10)\n",
        "print(f\"Top-10 Recommendations for Pop Model:\\n{pop_topk_recs[:5]}\")  # Print first 5 recommendations for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFmyOLsKWW3t",
        "outputId": "25a12a77-588e-4de5-8b11-106281bd9ba1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Top-K (10) Recommendations for each model...\n",
            "Top-10 Recommendations for BPR Model:\n",
            "[array([1736,  358,   53, 2041,   50, 1733, 2087, 1744,  290,  102]), array([1736, 2041, 1733, 2087, 1900, 1785, 1715, 1841, 1845, 1931]), array([1736, 2041, 1733, 1900, 1785, 2087, 1715, 1845, 1931, 1841]), array([1736, 2041,   53, 1733,  358,   50, 1785, 1900, 1715, 1840]), array([1736, 2041, 1733,  358, 1785,   53, 1900,   50, 1715,  102])]\n",
            "Top-10 Recommendations for ItemKNN Model:\n",
            "[array([1824, 1707, 2087, 1820, 2048, 1962, 2160, 1709, 1786, 1781]), array([1931, 1845, 1796, 1715, 1875, 1785, 1900, 1741, 1863, 2005]), array([1784, 1741, 1785, 1924, 1938, 1802, 2041, 1875, 1783, 2155]), array([1785, 1796, 1900, 1931, 1845, 2041, 1736, 1923, 1786, 1875]), array([ 102,  217,  113,  103, 1785,  248,  348,  322,  162,   54])]\n",
            "Top-10 Recommendations for Pop Model:\n",
            "[array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78]), array([ 32,  53, 137, 192, 157, 210, 290, 358, 190,  78])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def greedy_rerank(model, dataloader, dataset, topk=10, diversity_weight=0.5):\n",
        "    \"\"\"\n",
        "    Greedy re-ranking to balance relevance (model's score) and diversity\n",
        "    among the recommended items.\n",
        "\n",
        "    :param model: The recommendation model (BPR, ItemKNN, or Pop)\n",
        "    :param dataloader: The test dataloader for generating recommendations\n",
        "    :param dataset: The dataset object to access item_num\n",
        "    :param topk: Number of items to recommend after re-ranking (default: 10)\n",
        "    :param diversity_weight: Weight controlling the trade-off between relevance and diversity (0 = no diversity, 1 = max diversity)\n",
        "    :return: Re-ranked top-k recommendations\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    re_ranked_recommendations = []  # Placeholder for re-ranked recommendations\n",
        "    num_items = dataset.item_num  # Number of items in the dataset\n",
        "\n",
        "    for data in dataloader:\n",
        "        interaction = data[0]  # Get interaction tensor\n",
        "        scores = model.full_sort_predict(interaction).squeeze()  # Predict scores for all items and flatten\n",
        "        initial_topk_items = torch.topk(scores, k=topk*2, dim=-1).indices  # Get initial 2x top-k items\n",
        "\n",
        "        selected_items = []  # Placeholder for selected items after re-ranking\n",
        "\n",
        "        # Add the first item (highest relevance score)\n",
        "        selected_items.append(initial_topk_items[0].item())\n",
        "\n",
        "        # Greedily add items to maximize diversity\n",
        "        for _ in range(1, topk):\n",
        "            best_item = None\n",
        "            best_score = -float('inf')\n",
        "\n",
        "            # Loop over the remaining items and select the best one based on a trade-off between score and diversity\n",
        "            for item in initial_topk_items:\n",
        "                if item.item() in selected_items:\n",
        "                    continue  # Skip already selected items\n",
        "\n",
        "                if item.item() >= num_items:  # Ensure item index is valid\n",
        "                    continue  # Skip items that are out of bounds\n",
        "\n",
        "                # Different logic for models without embeddings\n",
        "                if hasattr(model, 'item_embedding'):  # BPR model with embeddings\n",
        "                    # Calculate diversity: Use cosine similarity\n",
        "                    diversity = 0\n",
        "                    for selected_item in selected_items:\n",
        "                        if selected_item >= num_items:  # Ensure selected_item index is valid\n",
        "                            continue\n",
        "\n",
        "                        sim = F.cosine_similarity(model.item_embedding.weight[item].unsqueeze(0),\n",
        "                                                  model.item_embedding.weight[selected_item].unsqueeze(0)).item()\n",
        "                        diversity += 1 - sim  # Higher difference = more diversity\n",
        "\n",
        "                    diversity = diversity / len(selected_items)  # Average diversity for the current item\n",
        "                else:\n",
        "                    # For models like ItemKNN or Pop, we'll just consider the relevance scores\n",
        "                    diversity = 0\n",
        "\n",
        "                # Relevance score for the current item\n",
        "                score = scores[item].item()\n",
        "\n",
        "                # Combine relevance and diversity into a final score\n",
        "                combined_score = (1 - diversity_weight) * score + diversity_weight * diversity\n",
        "\n",
        "                # Select the item with the best combined score\n",
        "                if combined_score > best_score:\n",
        "                    best_score = combined_score\n",
        "                    best_item = item.item()\n",
        "\n",
        "            # Add the best item to the selected items\n",
        "            if best_item is not None:\n",
        "                selected_items.append(best_item)\n",
        "\n",
        "        re_ranked_recommendations.append(selected_items)\n",
        "\n",
        "    return re_ranked_recommendations\n",
        "\n",
        "\n",
        "# Apply greedy re-ranking for each model's recommendations\n",
        "print(\"Applying Greedy Re-ranking for each model...\")\n",
        "\n",
        "# BPR Re-ranked Recommendations (uses item embeddings)\n",
        "bpr_re_ranked_recs = greedy_rerank(bpr_model, bpr_dataloader_test, bpr_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for BPR Model:\\n{bpr_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations\n",
        "\n",
        "# ItemKNN Re-ranked Recommendations (without item embeddings)\n",
        "itemknn_re_ranked_recs = greedy_rerank(itemknn_model, itemknn_dataloader_test, itemknn_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for ItemKNN Model:\\n{itemknn_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations\n",
        "\n",
        "# Pop Re-ranked Recommendations (without item embeddings)\n",
        "pop_re_ranked_recs = greedy_rerank(pop_model, pop_dataloader_test, pop_dataset, topk=10, diversity_weight=0.5)\n",
        "print(f\"Re-ranked Top-10 Recommendations for Pop Model:\\n{pop_re_ranked_recs[:5]}\")  # Print first 5 re-ranked recommendations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMFJQTW9Ks8R",
        "outputId": "199b1538-ed78-4765-b89b-df4faaca8c5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying Greedy Re-ranking for each model...\n",
            "Re-ranked Top-10 Recommendations for BPR Model:\n",
            "[[1736, 358, 53, 50, 290, 102, 158, 61, 190], [1736], [1736], [1736, 53, 358, 50, 158, 102, 61, 404, 217], [1736, 358, 53, 50, 102, 217, 32, 162]]\n",
            "Re-ranked Top-10 Recommendations for ItemKNN Model:\n",
            "[[1824], [1931], [1784], [1785], [102, 217, 113, 103, 248, 348, 322, 162, 54, 192]]\n",
            "Re-ranked Top-10 Recommendations for Pop Model:\n",
            "[[1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358], [1820, 192, 290, 53, 32, 78, 210, 137, 190, 358]]\n"
          ]
        }
      ]
    }
  ]
}